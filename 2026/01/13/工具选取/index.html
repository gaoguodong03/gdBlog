<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>工具选取 | 果冻小配方</title><meta name="author" content="GuoDong"><meta name="copyright" content="GuoDong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1. AutoTool: 高效工具选择框架（2025年11月）论文信息：《AutoTool: Efficient Tool Selection for Large Language Model Agents》（已被 AAAI 2026 录用）arxiv​ 核心创新：该论文指出，当前 ReAct 等框架存在的主要瓶颈是工具选择的高推理成本。作者提出了基于图的 AutoTool 框架，核心观察是工具使">
<meta property="og:type" content="article">
<meta property="og:title" content="工具选取">
<meta property="og:url" content="https://gaoguodong03.github.io/gdBlog/2026/01/13/%E5%B7%A5%E5%85%B7%E9%80%89%E5%8F%96/index.html">
<meta property="og:site_name" content="果冻小配方">
<meta property="og:description" content="1. AutoTool: 高效工具选择框架（2025年11月）论文信息：《AutoTool: Efficient Tool Selection for Large Language Model Agents》（已被 AAAI 2026 录用）arxiv​ 核心创新：该论文指出，当前 ReAct 等框架存在的主要瓶颈是工具选择的高推理成本。作者提出了基于图的 AutoTool 框架，核心观察是工具使">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gaoguodong03.github.io/gdBlog/img/logoLLM.png">
<meta property="article:published_time" content="2026-01-12T16:00:00.000Z">
<meta property="article:modified_time" content="2026-01-13T07:00:51.686Z">
<meta property="article:author" content="GuoDong">
<meta property="article:tag" content="Agent">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="ToolSection">
<meta property="article:tag" content="架构">
<meta property="article:tag" content="调研">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gaoguodong03.github.io/gdBlog/img/logoLLM.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "工具选取",
  "url": "https://gaoguodong03.github.io/gdBlog/2026/01/13/%E5%B7%A5%E5%85%B7%E9%80%89%E5%8F%96/",
  "image": "https://gaoguodong03.github.io/gdBlog/img/logoLLM.png",
  "datePublished": "2026-01-12T16:00:00.000Z",
  "dateModified": "2026-01-13T07:00:51.686Z",
  "author": [
    {
      "@type": "Person",
      "name": "GuoDong",
      "url": "https://gaoguodong03.github.io/gdBlog"
    }
  ]
}</script><link rel="shortcut icon" href="/gdBlog/img/logo.jpg"><link rel="canonical" href="https://gaoguodong03.github.io/gdBlog/2026/01/13/%E5%B7%A5%E5%85%B7%E9%80%89%E5%8F%96/index.html"><link rel="preconnect"/><link rel="stylesheet" href="/gdBlog/css/index.css"><link rel="stylesheet" href="/gdBlog/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/gdBlog/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: '/gdBlog/pluginsSrc/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '工具选取',
  isHighlightShrink: true,
  isToc: true,
  pageType: 'post'
}</script><style>#article-container.post-content h1:before, h2:before, h3:before, h4:before, h5:before, h6:before { -webkit-animation: avatar_turn_around 1s linear infinite; -moz-animation: avatar_turn_around 1s linear infinite; -o-animation: avatar_turn_around 1s linear infinite; -ms-animation: avatar_turn_around 1s linear infinite; animation: avatar_turn_around 1s linear infinite; }</style><!-- hexo injector head_end start --><link rel="stylesheet" href="/gdBlog/./css/categorybar.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 8.0.0"></head><body><div id="web_bg" style="background-image: url(/gdBlog/img/bg1.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/gdBlog/img/touxiang.jpg" onerror="this.onerror=null;this.src='/gdBlog/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/gdBlog/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/gdBlog/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/gdBlog/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/gdBlog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/link/"><i class="fa-fw fas fa-link"></i><span> 书签</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/gdBlog/./img/logoLLM.png);"><nav id="nav"><!-- 左侧博客信息区域--><span id="blog-info"><a class="nav-site-title" href="/gdBlog/"><img class="site-icon" src="/gdBlog/img/logo.jpg" alt="Logo"><span class="site-name">果冻小配方</span></a><a class="nav-page-title" href="/gdBlog/"><span class="site-name">工具选取</span></a></span><!-- 新增的导航菜单容器（居中布局关键）--><div id="nav-menus-container"><!-- 菜单主体部分--><div id="menus"><!-- 搜索按钮--><!-- 菜单项--><div class="menus_items"><div class="menus_item"><a class="site-page" href="/gdBlog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/link/"><i class="fa-fw fas fa-link"></i><span> 书签</span></a></div></div></div><!-- 移动端汉堡菜单按钮（保持原位置）--><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">工具选取</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-01-12T16:00:00.000Z" title="发表于 2026-01-13 00:00:00">2026-01-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-13T07:00:51.686Z" title="更新于 2026-01-13 15:00:51">2026-01-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/gdBlog/categories/%E6%9E%9C%E5%86%BB%E7%9A%84%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/">果冻的理论学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">5.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>18分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="1-AutoTool-高效工具选择框架（2025年11月）"><a href="#1-AutoTool-高效工具选择框架（2025年11月）" class="headerlink" title="1. AutoTool: 高效工具选择框架（2025年11月）"></a>1. AutoTool: 高效工具选择框架（2025年11月）</h2><p><strong>论文信息</strong>：《AutoTool: Efficient Tool Selection for Large Language Model Agents》（已被 AAAI 2026 录用）<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14650">arxiv</a>​</p>
<p><strong>核心创新</strong>：该论文指出，当前 ReAct 等框架存在的主要瓶颈是<strong>工具选择的高推理成本</strong>。作者提出了基于图的 AutoTool 框架，核心观察是<strong>工具使用惯性</strong>（tool usage inertia）——即工具调用往往遵循可预测的顺序模式。</p>
<p><strong>技术方案</strong>：</p>
<ul>
<li><p>从历史智能体轨迹构建有向图，节点代表工具，边的权重代表转移概率</p>
</li>
<li><p>通过图遍历进行工具选择，最小化 LLM 推理</p>
</li>
<li><p>集成参数级信息优化工具输入生成</p>
</li>
<li><p>不仅处理工具名称，还处理参数值</p>
</li>
</ul>
<p><strong>实验结果</strong>：</p>
<ul>
<li><p>推理成本降低 <strong>30%</strong>，同时保持竞争力的任务完成率</p>
</li>
<li><p>在多个智能体任务上验证有效性</p>
</li>
</ul>
<h2 id="实验进度："><a href="#实验进度：" class="headerlink" title="实验进度："></a>实验进度：</h2><p>评估脚本已可正常运行，但 API 调用存在超时问题，可能需要：</p>
<ul>
<li><p>检查 API 配置（base_url 和模型名称）</p>
</li>
<li><p>增加超时时间设置</p>
</li>
<li><p>检查网络连接</p>
</li>
</ul>
<h3 id="本次会话总结"><a href="#本次会话总结" class="headerlink" title="本次会话总结"></a>本次会话总结</h3><h3 id="2-修复了多个代码问题"><a href="#2-修复了多个代码问题" class="headerlink" title="2. 修复了多个代码问题"></a>2. 修复了多个代码问题</h3><p>pandas 兼容性问题：</p>
<ul>
<li><p>文件：agentboard&#x2F;utils&#x2F;logging&#x2F;logger.py</p>
</li>
<li><p>修复：将 DataFrame.append() 改为 pd.concat()（pandas 2.0+ 兼容）</p>
</li>
</ul>
<p>AlfWorld 环境初始化问题：</p>
<ul>
<li><p>文件：agentboard&#x2F;environment&#x2F;alfworld&#x2F;alfworld_env.py</p>
</li>
<li><p>修复：使用 get_environment() 函数替代直接访问类属性</p>
</li>
</ul>
<p>log_path 属性缺失：</p>
<ul>
<li><p>文件：agentboard&#x2F;tasks&#x2F;alfworld.py</p>
</li>
<li><p>修复：在 <strong>init</strong> 中添加 self.log_path &#x3D; log_path</p>
</li>
</ul>
<h3 id="3-解决了环境配置问题"><a href="#3-解决了环境配置问题" class="headerlink" title="3. 解决了环境配置问题"></a>3. 解决了环境配置问题</h3><ul>
<li><p>Python 版本：从 3.8 升级到 3.9（解决 textworld 兼容性）</p>
</li>
<li><p>依赖安装：安装了所有必需的 Python 包</p>
</li>
<li><p>环境变量：配置了 PROJECT_PATH 和 PYTHONPATH</p>
</li>
<li><p>数据文件：创建了符号链接指向正确的数据位置</p>
</li>
<li><p>工具描述文件：修复了路径配置问题</p>
</li>
</ul>
<h3 id="4-优化了配置"><a href="#4-优化了配置" class="headerlink" title="4. 优化了配置"></a>4. 优化了配置</h3><ul>
<li><p>限制任务数量：在配置文件中添加 num_exam: 3 用于快速测试</p>
</li>
<li><p>修复了 .env 中的 TOOL_DESC_FILE 路径配置</p>
</li>
</ul>
<hr>
<h2 id="2-EASYTOOL-统一工具指令框架（2025年4月，NAACL）"><a href="#2-EASYTOOL-统一工具指令框架（2025年4月，NAACL）" class="headerlink" title="2. EASYTOOL: 统一工具指令框架（2025年4月，NAACL）"></a>2. EASYTOOL: 统一工具指令框架（2025年4月，NAACL）</h2><p><strong>论文信息</strong>：《Enhancing LLM-based Agents with Concise Tool Instruction》发表于 NAACL 2025<a target="_blank" rel="noopener" href="https://aclanthology.org/2025.naacl-long.44.pdf">aclanthology</a>​</p>
<p><strong>核心问题</strong>：工具文档存在<strong>不一致性、冗余性、不完整性</strong>问题：</p>
<ul>
<li><p>不同来源的工具文档格式多样（RapidAPI、HuggingFace 等）</p>
</li>
<li><p>平均每个工具文档包含约 2,530 个 token，但核心信息占比小</p>
</li>
<li><p>工具文档缺乏使用场景示例和参数说明</p>
</li>
</ul>
<p><strong>方法论</strong>（四阶段框架）：</p>
<ol>
<li><p><strong>任务规划</strong>：将用户请求分解为子任务</p>
</li>
<li><p><strong>工具检索</strong>：基于相似度选择候选工具集合</p>
</li>
<li><p><strong>工具选择</strong>（核心）：LLM 从候选工具中选择最适合的工具</p>
</li>
<li><p><strong>工具执行</strong>：执行工具，失败时重试</p>
</li>
</ol>
<p><strong>EASYTOOL 的核心创新</strong>：</p>
<ul>
<li><p><strong>第一阶段</strong>：使用 LLM（ChatGPT）自动生成高质量工具描述，去除冗余信息，只保留核心功能</p>
</li>
<li><p><strong>第二阶段</strong>：构建工具功能指南，包含参数列表和使用场景示例</p>
</li>
</ul>
<p><strong>实验数据</strong>：</p>
<table>
<thead>
<tr>
<th>数据集</th>
<th>原始文档大小</th>
<th>EASYTOOL 处理后</th>
<th>压缩率</th>
</tr>
</thead>
<tbody><tr>
<td>ToolBench</td>
<td>2,530 tokens</td>
<td>748 tokens</td>
<td><strong>70.43%</strong></td>
</tr>
<tr>
<td>RestBench</td>
<td>3,881 tokens</td>
<td>103 tokens</td>
<td><strong>97.35%</strong></td>
</tr>
</tbody></table>
<p><strong>在 ToolBench 上的工具选择精度提升</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>原始文档</th>
<th>+EASYTOOL</th>
<th>提升</th>
</tr>
</thead>
<tbody><tr>
<td>ChatGPT</td>
<td>~30-50% (50个候选工具时)</td>
<td>70-80%</td>
<td><strong>+40%</strong></td>
</tr>
<tr>
<td>GPT-4</td>
<td>~40-55%</td>
<td>75-85%</td>
<td><strong>+35%</strong></td>
</tr>
</tbody></table>
<p><strong>实验平台</strong>：三个不同任务的基准测试</p>
<ul>
<li><p><strong>ToolBench</strong> (I2-Category&#x2F;I3-Instruction)：复杂用户请求，需要多工具调用</p>
</li>
<li><p><strong>RestBench</strong>：真实网络服务场景</p>
</li>
<li><p><strong>FuncQA</strong>：数学推理问题</p>
</li>
</ul>
<p><strong>主要成果</strong>：</p>
<ul>
<li><p>工具名称错误率从 <strong>8%</strong> 降至 <strong>0%</strong>（ChatGPT with EASYTOOL）</p>
</li>
<li><p>参数错误率从 <strong>25%</strong> 降至 <strong>6%</strong>（GPT-4）</p>
</li>
<li><p>成功率平均提升 <strong>50+%</strong><a target="_blank" rel="noopener" href="https://aclanthology.org/2025.naacl-long.44.pdf">aclanthology</a>​</p>
</li>
</ul>
<p><strong>代码和可复现性</strong>：✅ 官方代码已发布</p>
<ul>
<li><p>GitHub: <a target="_blank" rel="noopener" href="https://github.com/microsoft/JARVIS/tree/main/easytool">https://github.com/microsoft/JARVIS/tree/main/easytool</a></p>
</li>
<li><p>包含完整的数据处理管道和评估脚本</p>
</li>
</ul>
<hr>
<h2 id="3-Agent-as-Tool-分层决策框架（2025年7月）"><a href="#3-Agent-as-Tool-分层决策框架（2025年7月）" class="headerlink" title="3. Agent-as-Tool: 分层决策框架（2025年7月）"></a>3. Agent-as-Tool: 分层决策框架（2025年7月）</h2><p><strong>论文信息</strong>：《Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning》<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.01489">arxiv</a>​</p>
<p><strong>核心问题</strong>：以往研究同时处理工具调用和推理过程，导致模型需要处理工具输出中的冗余信息，增加推理负担。</p>
<p><strong>创新方案</strong>：提出<strong>分层框架</strong>，将工具调用过程与推理过程解耦：</p>
<ul>
<li><p>上层代理专注于<strong>逻辑推理</strong></p>
</li>
<li><p>下层代理负责<strong>工具调用执行</strong></p>
</li>
<li><p>两层通过清晰的信息接口通信</p>
</li>
</ul>
<p><strong>实验成果</strong>：</p>
<ul>
<li><p>在 Bamboogle 基准上实现 <strong>63.2% exact match</strong>（相比 Search-R1 提升 <strong>4.8%</strong>）</p>
</li>
<li><p>仅需 180 个样本的强化学习微调</p>
</li>
</ul>
<p><strong>可复现性</strong>：代码示例在论文附录中提供，支持重现</p>
<hr>
<h2 id="4-ARTIST-强化学习与工具集成框架（2024年5月）"><a href="#4-ARTIST-强化学习与工具集成框架（2024年5月）" class="headerlink" title="4. ARTIST: 强化学习与工具集成框架（2024年5月）"></a>4. ARTIST: 强化学习与工具集成框架（2024年5月）</h2><p><strong>论文信息</strong>：《Agentic Reasoning &amp; Tool Integration for LLMs via RL》<a target="_blank" rel="noopener" href="https://arxiv.org/html/2505.01441v1">arxiv</a>​</p>
<p><strong>创新点</strong>：首个将智能体推理、动态工具选择和强化学习紧密结合的框架</p>
<p><strong>方法特色</strong>：</p>
<ul>
<li><p>将工具使用视为<strong>一等操作</strong>（first-class operation），与文本推理无缝集成</p>
</li>
<li><p>推理链中交错使用：文本思考 → 工具调用 → 工具输出 → 迭代推理</p>
</li>
<li><p>通过 RL 学习何时、如何、调用哪个工具</p>
</li>
</ul>
<p><strong>案例</strong>：数学奥林匹克问题</p>
<ul>
<li><p>传统方法：纯文本推理导致符号操作错误</p>
</li>
<li><p>ARTIST：调用 Python 解释器，使用 SymPy 库，将结果集成回推理链，实现自我纠正</p>
</li>
</ul>
<p><strong>效果</strong>：新的推理范式展现了 emergent agentic behaviors，包括：</p>
<ul>
<li><p>自适应工具选择</p>
</li>
<li><p>迭代自我纠正</p>
</li>
<li><p>上下文感知多步推理</p>
</li>
</ul>
<hr>
<h2 id="5-A²FM-自适应多模式代理基础模型（2025年10月）"><a href="#5-A²FM-自适应多模式代理基础模型（2025年10月）" class="headerlink" title="5. A²FM: 自适应多模式代理基础模型（2025年10月）"></a>5. A²FM: 自适应多模式代理基础模型（2025年10月）</h2><p><strong>论文信息</strong>：《A²FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning》<a target="_blank" rel="noopener" href="https://arxiv.org/html/2510.12838v3">arxiv</a>​</p>
<p><strong>核心创新</strong>：针对不同任务自适应选择操作模式</p>
<p><strong>三种模式</strong>：</p>
<ol>
<li><p><strong>即时模式</strong>（Instant）：直接输出答案，最小化思考</p>
</li>
<li><p><strong>推理模式</strong>（Reasoning）：提供思维链，适合逻辑推理</p>
</li>
<li><p><strong>智能体模式</strong>（Agentic）：交错推理与工具调用，适合需要实时信息的任务</p>
</li>
</ol>
<p><strong>工具选择机制</strong>：根据任务类型自动分类</p>
<p>text</p>
<p><code>任务分析 → 需要实时信息？→ YES → 智能体模式            → 需要复杂推理？ → YES → 推理模式           → 简单任务？    → YES → 即时模式</code></p>
<hr>
<h2 id="重点基准和评估框架"><a href="#重点基准和评估框架" class="headerlink" title="重点基准和评估框架"></a>重点基准和评估框架</h2><h2 id="GTA-通用工具智能体基准（NeurIPS-2024）"><a href="#GTA-通用工具智能体基准（NeurIPS-2024）" class="headerlink" title="GTA: 通用工具智能体基准（NeurIPS 2024）"></a>GTA: 通用工具智能体基准（NeurIPS 2024）</h2><p><strong>数据集特点</strong> ：<a target="_blank" rel="noopener" href="https://github.com/open-compass/GTA">github</a>​</p>
<ul>
<li><p><strong>229 个真实用户查询</strong>（手工编写，隐含工具需求）</p>
</li>
<li><p><strong>14 个真实部署的工具</strong>，跨越感知、操作、逻辑、创意四类</p>
</li>
<li><p><strong>真实多模态输入</strong>：空间场景、网页截图、表格、代码片段、打印&#x2F;手写材料</p>
</li>
</ul>
<p><strong>与其他基准的对比</strong>：</p>
<ul>
<li><p>ToolBench&#x2F;APIBench：AI 生成查询，显式工具说明</p>
</li>
<li><p>GTA：真实查询，工具&#x2F;步骤隐式，更接近实际应用</p>
</li>
</ul>
<p><strong>评估指标（双模式）</strong>：</p>
<table>
<thead>
<tr>
<th>评估维度</th>
<th>指标</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><strong>逐步模式</strong></td>
<td>InstAcc</td>
<td>指令跟随精度</td>
</tr>
<tr>
<td></td>
<td>ToolAcc</td>
<td>工具选择精度</td>
</tr>
<tr>
<td></td>
<td>ArgAcc</td>
<td>参数预测精度</td>
</tr>
<tr>
<td></td>
<td>SummAcc</td>
<td>答案总结精度</td>
</tr>
<tr>
<td><strong>端到端模式</strong></td>
<td>AnsAcc</td>
<td>最终答案精度</td>
</tr>
<tr>
<td></td>
<td>P&#x2F;O&#x2F;L&#x2F;C F1</td>
<td>四类工具的 F1 分数</td>
</tr>
</tbody></table>
<p><strong>最新排行榜（2025年3月）</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>ToolAcc (%)</th>
<th>AnsAcc (%)</th>
</tr>
</thead>
<tbody><tr>
<td>Deepseek-V3</td>
<td>40.57</td>
<td>—</td>
</tr>
<tr>
<td>Qwen-Max-2.5</td>
<td><strong>58.35</strong></td>
<td><strong>41.73</strong></td>
</tr>
<tr>
<td>GPT-4o</td>
<td>—</td>
<td>41.52</td>
</tr>
<tr>
<td>DeepSeek-R1-Llama-70B</td>
<td>7.72</td>
<td>13.09</td>
</tr>
<tr>
<td>Llama-3.1-8B-Instruct</td>
<td>24.24</td>
<td>8.78</td>
</tr>
</tbody></table>
<p><strong>可复现性</strong>：✅ 完整</p>
<ul>
<li><p>数据集：Hugging Face 已发布</p>
</li>
<li><p>工具部署代码：基于 AgentLego</p>
</li>
<li><p>评估管道：支持两种评估模式（逐步&#x2F;端到端）</p>
</li>
<li><p>GitHub: <a target="_blank" rel="noopener" href="https://github.com/open-compass/GTA">https://github.com/open-compass/GTA</a></p>
</li>
</ul>
<hr>
<h2 id="伯克利函数调用排行榜（BFCL）"><a href="#伯克利函数调用排行榜（BFCL）" class="headerlink" title="伯克利函数调用排行榜（BFCL）"></a>伯克利函数调用排行榜（BFCL）</h2><p><strong>评估维度</strong>：<a target="_blank" rel="noopener" href="https://symflower.com/en/company/blog/2025/function-calling-llm-agents/">symflower</a>​</p>
<ol>
<li><p><strong>相关性检测</strong>：判断何时<strong>不调用</strong>函数</p>
</li>
<li><p><strong>多轮交互</strong>：在多轮对话中保持上下文</p>
</li>
<li><p><strong>多步推理</strong>：顺序链式调用，前一个输出作为后一个输入</p>
</li>
<li><p><strong>并行函数调用</strong></p>
</li>
</ol>
<p><strong>基准规模</strong>：2,000+ 问题-函数-答案对，多种编程语言</p>
<p><strong>2025年最佳表现</strong>：<a target="_blank" rel="noopener" href="https://www.klavis.ai/blog/function-calling-and-agentic-ai-in-2025-what-the-latest-benchmarks-tell-us-about-model-performance">klavis</a>​</p>
<ul>
<li><p>GPT-5：<strong>52.56% pass@1</strong>（MCPMark 上）</p>
</li>
<li><p>成本效率：Qwen-3-Coder ($36.46&#x2F;run)</p>
</li>
</ul>
<hr>
<h2 id="MCPMark-基准（Model-Context-Protocol）"><a href="#MCPMark-基准（Model-Context-Protocol）" class="headerlink" title="MCPMark 基准（Model Context Protocol）"></a>MCPMark 基准（Model Context Protocol）</h2><p><strong>特点</strong>：127 个高质量任务，由领域专家和 AI 智能体联合创建</p>
<p><strong>测试能力</strong>：</p>
<ul>
<li><p>规则遵循</p>
</li>
<li><p>信息收集（通过外部工具）</p>
</li>
<li><p>信息推理与记忆（长上下文）</p>
</li>
<li><p>用户沟通</p>
</li>
</ul>
<p><strong>难度</strong>：模拟真实的动态对话，避免过拟合</p>
<hr>
<h2 id="重点开源项目和可复现的实现"><a href="#重点开源项目和可复现的实现" class="headerlink" title="重点开源项目和可复现的实现"></a>重点开源项目和可复现的实现</h2><h2 id="1-RepoMaster：存储库自主探索框架"><a href="#1-RepoMaster：存储库自主探索框架" class="headerlink" title="1. RepoMaster：存储库自主探索框架"></a>1. RepoMaster：存储库自主探索框架</h2><p><strong>项目信息</strong>：</p>
<ul>
<li><p>提交：2025年5月（arXiv:2505.21577）</p>
</li>
<li><p>GitHub: <a target="_blank" rel="noopener" href="https://github.com/QuantaAlpha/RepoMaster">https://github.com/QuantaAlpha/RepoMaster</a></p>
</li>
<li><p>许可证：开源（代码和演示材料公开）</p>
</li>
</ul>
<p><strong>核心创新</strong>：将 GitHub 存储库作为<strong>可组合的工具</strong>，通过结构化分析实现高效工具选择</p>
<p><strong>工具选择的层级化方法</strong>：</p>
<p>text</p>
<p><code>1. 混合结构映射    ├── 层级代码树（HCT）：包→模块→类→函数   ├── 函数调用图（FCG）：f_i → f_j（调用频率）   └── 模块依赖图（MDG）：m_i → m_j（耦合强度） 2. 核心组件识别    ├── 模块级评分：6个特征（依赖性、复杂度、使用、语义、文档、Git）   ├── 类级精细化：基于方法数量和调用频率   └── 选择 TOP-K 类作为核心组件 3. 自主探索与执行    ├── 代码查看工具：HCT 导航   ├── 依赖分析工具：FCG/MDG 追踪   └── 搜索工具：关键字匹配</code></p>
<p><strong>性能基准</strong>：</p>
<p>在 <strong>GitTaskBench</strong>（18个存储库，54个任务）上：</p>
<table>
<thead>
<tr>
<th>框架</th>
<th>模型</th>
<th>执行完成率 (%)</th>
<th>任务通过率 (%)</th>
<th>Token 消耗 (k)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>RepoMaster</strong></td>
<td>Claude 3.5</td>
<td><strong>75.92</strong></td>
<td><strong>62.96</strong></td>
<td><strong>154</strong></td>
</tr>
<tr>
<td>OpenHands</td>
<td>Claude 3.5</td>
<td>53.70</td>
<td>40.74</td>
<td>2,883</td>
</tr>
<tr>
<td>SWE-Agent</td>
<td>Claude 3.5</td>
<td>41.67</td>
<td>22.23</td>
<td>456</td>
</tr>
</tbody></table>
<p><strong>关键优势</strong>：</p>
<ul>
<li><p><strong>+22 百分点</strong> vs OpenHands（任务通过率）</p>
</li>
<li><p><strong>95% token 节省</strong> vs 基线</p>
</li>
<li><p><strong>可解释的工具选择过程</strong>（通过知识图）</p>
</li>
</ul>
<p><strong>可复现步骤</strong>（完整文档）：</p>
<ol>
<li><p>克隆存储库并配置环境</p>
</li>
<li><p>使用 LMDeploy 部署模型服务</p>
</li>
<li><p>使用 AgentLego 部署工具</p>
</li>
<li><p>通过 OpenCompass 运行评估</p>
</li>
</ol>
<p><strong>代码示例可获得性</strong>：✅ 完整的案例研究和日志在论文附录中</p>
<hr>
<h2 id="2-EnvX：存储库智能体化框架"><a href="#2-EnvX：存储库智能体化框架" class="headerlink" title="2. EnvX：存储库智能体化框架"></a>2. EnvX：存储库智能体化框架</h2><p><strong>项目信息</strong>：</p>
<ul>
<li><p>提交：2025年4月（arXiv:2509.08088）</p>
</li>
<li><p>同行评审：已发表</p>
</li>
<li><p>代码：待发布</p>
</li>
</ul>
<p><strong>核心创新</strong>：将任意 GitHub 存储库转变为<strong>具有通信能力的智能体</strong></p>
<p><strong>三阶段工具选择&#x2F;使用流程</strong>：</p>
<p>text</p>
<p><code>阶段1：TODO 引导的环境初始化 ├── 分析存储库文档（README） ├── 自动生成结构化 TODO 列表 ├── 执行依赖安装、数据下载、验证数据 └── 迭代修订 TODO 列表 阶段2：人类对齐的智能体自动化 ├── 构造存储库特定的智能体 ├── 支持自然语言查询 └── 通过工具中介进行任务执行 阶段3：智能体间通信（A2A 协议） ├── 生成智能体卡片 ├── 提取智能体技能 └── 多智能体协作</code></p>
<p><strong>六类工具集成</strong>：</p>
<ol>
<li><p><strong>基础工具</strong>：推理、文件操作、脚本执行</p>
</li>
<li><p><strong>文件下载工具</strong>：获取数据集和模型</p>
</li>
<li><p><strong>TODO 管理工具</strong>：初始化工作流验证</p>
</li>
<li><p><strong>依赖管理工具</strong>：统一处理 requirements.txt、Conda</p>
</li>
<li><p><strong>代码知识图工具</strong>：语义分析和查询</p>
</li>
<li><p><strong>A2A 生成工具</strong>：多智能体通信</p>
</li>
</ol>
<p><strong>性能数据</strong>（GitTaskBench）：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>执行完成率 (%)</th>
<th>任务通过率 (%)</th>
<th>相对提升 vs OpenHands</th>
</tr>
</thead>
<tbody><tr>
<td>Claude 3.7 Sonnet</td>
<td>74.07</td>
<td>51.85</td>
<td><strong>+7.6%</strong> (ECR)</td>
</tr>
<tr>
<td>GPT-4.1</td>
<td>68.52</td>
<td>46.30</td>
<td><strong>+23.4%</strong> (vs OpenHands)</td>
</tr>
</tbody></table>
<p><strong>Token 效率</strong>：Claude 3.7 下消耗 <strong>562k tokens&#x2F;任务</strong> vs OpenHands 的 <strong>9.5M tokens</strong>（强大性能下更高效）</p>
<p><strong>可复现性</strong>：🔧 实现细节部分文档</p>
<ul>
<li><p>完整的系统工作流在论文第 3 节</p>
</li>
<li><p>案例研究在第 4.4 节</p>
</li>
<li><p>代码待发布</p>
</li>
</ul>
<hr>
<h2 id="3-LangGraph-LangChain（生产级框架，2025年）"><a href="#3-LangGraph-LangChain（生产级框架，2025年）" class="headerlink" title="3. LangGraph + LangChain（生产级框架，2025年）"></a>3. LangGraph + LangChain（生产级框架，2025年）</h2><p><strong>官方状态</strong>：</p>
<ul>
<li><p>LangChain 团队正式推荐所有新代理实现使用 <strong>LangGraph</strong></p>
</li>
<li><p>标志性发布：《How to think about agent frameworks》（2025）</p>
</li>
</ul>
<p><strong>工具选择集成</strong>：</p>
<p>python</p>
<p><code>from typing import Annotated from langchain_openai import ChatOpenAI from langchain_core.tools import tool from langgraph.checkpoint.memory import MemorySaver from langgraph.prebuilt import create_react_agent # 定义工具 @tool def search_database(query: str) -&gt; str:     &quot;&quot;&quot;    搜索内部数据库以获取客户信息。    当用户询问客户数据、订单或账户信息时使用。    &quot;&quot;&quot;    # 实现...    pass # 创建 ReAct 智能体 tools = [search_database, calculate_metrics, send_notification] memory = MemorySaver() agent = create_react_agent(     model=ChatOpenAI(model=&quot;gpt-4&quot;),    tools=tools,    checkpointer=memory,    state_modifier=&quot;You are a helpful business intelligence assistant...&quot; )</code></p>
<p><strong>工具选择工作流</strong>：</p>
<ol>
<li><p>LLM 分析用户请求</p>
</li>
<li><p>审查可用工具及其描述</p>
</li>
<li><p>根据上下文推理选择工具</p>
</li>
<li><p>调用所选工具</p>
</li>
<li><p>处理结果并决策是否继续（迭代）</p>
</li>
<li><p>将状态保存到检查点</p>
</li>
</ol>
<p><strong>2025 年新增特性</strong>：</p>
<ul>
<li><p><strong>显式状态模式</strong>：使用 TypedDict 和 Annotated 类型</p>
</li>
<li><p><strong>Reducer 函数</strong>：管理并发智能体的安全状态更新</p>
</li>
<li><p><strong>健壮检查点</strong>：支持并行任务执行和恢复</p>
</li>
<li><p><strong>向量数据库集成</strong>：Pinecone、Weaviate、Chroma 支持</p>
</li>
</ul>
<p><strong>代码可用性</strong>：✅ 完全开源</p>
<ul>
<li><p>GitHub: <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langgraph">https://github.com/langchain-ai/langgraph</a></p>
</li>
<li><p>官方文档和教程完整</p>
</li>
<li><p>生产部署示例</p>
</li>
</ul>
<hr>
<h2 id="4-Anthropic-多智能体研究系统（2025年6月）"><a href="#4-Anthropic-多智能体研究系统（2025年6月）" class="headerlink" title="4. Anthropic 多智能体研究系统（2025年6月）"></a>4. Anthropic 多智能体研究系统（2025年6月）</h2><p><strong>项目成果</strong>：《How we built our multi-agent research system》<a target="_blank" rel="noopener" href="https://www.anthropic.com/engineering/multi-agent-research-system">anthropic</a>​</p>
<p><strong>工具选择设计原则</strong>：</p>
<ol>
<li><p><strong>显式启发式规则</strong>：检查所有可用工具，匹配工具使用与用户意图</p>
</li>
<li><p><strong>网络搜索作为工具</strong>：将信息检索作为第一等公民</p>
</li>
<li><p><strong>并行工具调用</strong>：加速多源信息采集</p>
</li>
</ol>
<p><strong>架构模式</strong>：</p>
<p>text</p>
<p><code>用户查询   ↓ 主导智能体（Claude Opus 4）   ├→ 策略规划  ├→ 生成并发子任务  └→ 生成子智能体（Claude Sonnet 4）       ├→ 搜索工具调用       ├→ 迭代查询优化       └→ 信息过滤返回 最终答案组装</code></p>
<p><strong>关键性能指标</strong>：</p>
<ul>
<li><p>在宽度优先查询上性能提升 <strong>90.2%</strong>（vs 单智能体）</p>
</li>
<li><p>仅需三个因素解释 <strong>95%</strong> 的性能差异：</p>
<ul>
<li><p>Token 使用量：<strong>80%</strong></p>
</li>
<li><p>工具调用次数：<strong>10%</strong></p>
</li>
<li><p>模型选择：<strong>5%</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>工具优化案例</strong>：</p>
<ul>
<li><p>工具测试智能体发现工具中的 bug 并自动重写工具描述</p>
</li>
<li><p>结果：<strong>40% 的任务完成时间加速</strong></p>
</li>
</ul>
<p><strong>可复现性</strong>：✅ 完整设计文档</p>
<ul>
<li><p>系统架构详细描述</p>
</li>
<li><p>提示词工程最佳实践</p>
</li>
<li><p>扩展思考集成指南</p>
</li>
</ul>
<hr>
<h2 id="5-ToolBench-和-ToolLLaMA（2023-2025持续更新）"><a href="#5-ToolBench-和-ToolLLaMA（2023-2025持续更新）" class="headerlink" title="5. ToolBench 和 ToolLLaMA（2023-2025持续更新）"></a>5. ToolBench 和 ToolLLaMA（2023-2025持续更新）</h2><p><strong>项目信息</strong>：</p>
<ul>
<li><p>GitHub: <a target="_blank" rel="noopener" href="https://github.com/OpenBMB/ToolBench">https://github.com/OpenBMB/ToolBench</a></p>
</li>
<li><p>数据集规模：自动构造的大规模工具学习数据集</p>
</li>
<li><p>论文：《ToolLLM: Facilitating Large Language Models to Master Tool Use》<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=dHng2O0Jjr">openreview</a>​</p>
</li>
</ul>
<p><strong>工具选择评估方法</strong>：</p>
<p>text</p>
<p><code>ToolEval（自动评估器） ├── 度量 1：工具调用准确性 │   └── 评估模型是否选择了正确的工具 ├── 度量 2：参数准确性 │   └── 评估工具参数是否正确 └── 集成方法：AlpacaEval 风格的 LLM 评估</code></p>
<p><strong>核心数据构造方法</strong>：</p>
<ol>
<li><p>使用 ChatGPT <strong>自动生成</strong> instruction-following 数据</p>
</li>
<li><p>包含单工具和多工具场景</p>
</li>
<li><p>支持<strong>深度优先搜索决策树</strong>算法，用于多轨迹推理扩展</p>
</li>
</ol>
<p><strong>神经 API 检索器</strong>：</p>
<ul>
<li><p>为每个指令推荐适当的 API</p>
</li>
<li><p>无需手动 API 选择</p>
</li>
<li><p>实现零样本泛化到未见 API</p>
</li>
</ul>
<p><strong>ToolLLaMA 性能</strong>：</p>
<ul>
<li><p>通过对 LLaMA 的微调达到 <strong>ChatGPT 级别</strong>的工具使用能力</p>
</li>
<li><p>在 APIBench（分布外数据集）上展示强大的零样本泛化</p>
</li>
</ul>
<p><strong>可复现性</strong>：✅ 完整</p>
<ul>
<li><p>预训练模型已发布（ToolLLaMA-2-7b-v2 等）</p>
</li>
<li><p>完整的训练管道和数据处理脚本</p>
</li>
<li><p>ToolEval 评估代码公开</p>
</li>
</ul>
<hr>
<h2 id="工具选择中的最新技术趋势"><a href="#工具选择中的最新技术趋势" class="headerlink" title="工具选择中的最新技术趋势"></a>工具选择中的最新技术趋势</h2><h2 id="1-效率优化的统计结构化方法"><a href="#1-效率优化的统计结构化方法" class="headerlink" title="1. 效率优化的统计结构化方法"></a>1. 效率优化的统计结构化方法</h2><p><strong>核心洞察</strong>（AutoTool）：工具使用并非随机，存在<strong>统计惯性</strong>。通过图模型学习这种模式，可显著降低 LLM 调用。</p>
<p><strong>应用场景</strong>：长序列任务中工具调用高度重复</p>
<hr>
<h2 id="2-多层信息剪枝"><a href="#2-多层信息剪枝" class="headerlink" title="2. 多层信息剪枝"></a>2. 多层信息剪枝</h2><p><strong>问题</strong>：LLM 上下文窗口有限，但工具文档庞大</p>
<p><strong>解决方案</strong>（EASYTOOL + RepoMaster）：</p>
<ul>
<li><p>代码级：AST 子树提取</p>
</li>
<li><p>文档级：块级检索和相关性排序</p>
</li>
<li><p>日志级：保留开始&#x2F;结束段，丢弃冗余输出</p>
</li>
</ul>
<p><strong>成效</strong>：95%+ token 节省，性能维持或改善</p>
<hr>
<h2 id="3-知识图驱动的工具导航"><a href="#3-知识图驱动的工具导航" class="headerlink" title="3. 知识图驱动的工具导航"></a>3. 知识图驱动的工具导航</h2><p><strong>创新</strong>（RepoMaster）：不将代码库视为黑盒，而是构造明确的结构表示</p>
<p>text</p>
<p><code>代码知识图 = {   模块依赖图（MDG）,  函数调用图（FCG）,  层级代码树（HCT） } 优先级评分 = PageRank(MDG) + 复杂度 + 使用频率 + 语义特征 选择 → TOP-K 核心组件 → 初始上下文</code></p>
<p><strong>优势</strong>：智能体具有<strong>可解释的工具选择理由</strong>，支持快速适应新存储库</p>
<hr>
<h2 id="4-分层与解耦架构"><a href="#4-分层与解耦架构" class="headerlink" title="4. 分层与解耦架构"></a>4. 分层与解耦架构</h2><p><strong>趋势</strong>（Agent-as-Tool, A²FM）：避免一个模块处理”理性思维 + 工具调用”这个复杂任务</p>
<p><strong>方案</strong>：</p>
<ul>
<li><p>上层专注推理</p>
</li>
<li><p>下层专注执行</p>
</li>
<li><p>清晰的接口和信息流</p>
</li>
</ul>
<p><strong>效果</strong>：推理质量改善，错误率下降</p>
<hr>
<h2 id="5-自适应模式选择"><a href="#5-自适应模式选择" class="headerlink" title="5. 自适应模式选择"></a>5. 自适应模式选择</h2><p><strong>新范式</strong>（A²FM）：不同任务需要不同的工具使用策略</p>
<p>text</p>
<p><code>即时模式    ← 简单查询，无需工具 推理模式    ← 需要逻辑推理，可能需要工具 智能体模式  ← 实时信息必需，大量工具调用</code></p>
<p><strong>关键</strong>：自动任务分类，匹配到最优模式</p>
<hr>
<h2 id="总体建议与最佳实践"><a href="#总体建议与最佳实践" class="headerlink" title="总体建议与最佳实践"></a>总体建议与最佳实践</h2><h2 id="学术研究方向"><a href="#学术研究方向" class="headerlink" title="学术研究方向"></a>学术研究方向</h2><ol>
<li><p><strong>可验证性</strong>：工具选择决策应有明确的推理链，支持事后审计</p>
</li>
<li><p><strong>泛化能力</strong>：测试在未见工具集上的表现（zero-shot）</p>
</li>
<li><p><strong>成本效益</strong>：同时优化任务完成率和 token 消耗</p>
</li>
<li><p><strong>多模态</strong>：处理图像、表格等富媒体作为工具输入</p>
</li>
</ol>
<h2 id="实践部署建议"><a href="#实践部署建议" class="headerlink" title="实践部署建议"></a>实践部署建议</h2><p><strong>选择框架时的关键因素</strong>：</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>推荐方案</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>生产关键系统</td>
<td>RepoMaster 或 LangGraph</td>
<td>可解释、高效、可维护</td>
</tr>
<tr>
<td>快速原型</td>
<td>CrewAI 或 Dynamiq</td>
<td>低代码、易上手</td>
</tr>
<tr>
<td>学术研究</td>
<td>GTA 或 ToolBench</td>
<td>完整数据集、标准评估</td>
</tr>
<tr>
<td>大规模部署</td>
<td>自定义系统+EASYTOOL</td>
<td>最大控制和优化空间</td>
</tr>
</tbody></table>
<p><strong>关键检查清单</strong>：</p>
<ul>
<li><p>✅ 评估工具集大小和复杂度</p>
</li>
<li><p>✅ 确定可接受的 token 预算</p>
</li>
<li><p>✅ 验证错误恢复机制</p>
</li>
<li><p>✅ 测试新工具的适应能力</p>
</li>
<li><p>✅ 监测生产中的工具选择准确率</p>
</li>
</ul>
<hr>
<h2 id="数据真实性声明"><a href="#数据真实性声明" class="headerlink" title="数据真实性声明"></a>数据真实性声明</h2><p>本报告中所有数据均来自：</p>
<ol>
<li><p><strong>已发表的学术论文</strong>（arXiv、会议proceedings）</p>
</li>
<li><p><strong>官方代码库和文档</strong>（GitHub、Hugging Face）</p>
</li>
<li><p><strong>官方基准评估结果</strong>（排行榜、开放排名）</p>
</li>
</ol>
<p><strong>无合成数据</strong>。所有定量指标均直接引自原始论文或官方发布的结果。</p>
<hr>
<h2 id="关键参考文献"><a href="#关键参考文献" class="headerlink" title="关键参考文献"></a>关键参考文献</h2><p>Jia, J., Li, Q. (2025). AutoTool: Efficient Tool Selection for Large Language Model Agents. AAAI 2026 accepted.<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14650">arxiv</a>​</p>
<p>Zhang, Y. (2025). Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning. arXiv:2507.01489.<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.01489">arxiv</a>​</p>
<p>Yuan, S., Song, K., et al. (2025). Enhancing LLM-based Agents with Concise Tool Instruction. NAACL 2025, pp. 951–972.<a target="_blank" rel="noopener" href="https://aclanthology.org/2025.naacl-long.44.pdf">aclanthology</a>​</p>
<p>Anthropic (2025). How we built our multi-agent research system.<a target="_blank" rel="noopener" href="https://www.anthropic.com/engineering/multi-agent-research-system">anthropic</a>​</p>
<p>(2024). Agentic Reasoning &amp; Tool Integration for LLMs via RL. arXiv:2505.01441.<a target="_blank" rel="noopener" href="https://arxiv.org/html/2505.01441v1">arxiv</a>​</p>
<p>(2025). A²FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning. arXiv:2510.12838v3.<a target="_blank" rel="noopener" href="https://arxiv.org/html/2510.12838v3">arxiv</a>​</p>
<p>Wang, J., et al. (2024). GTA: A Benchmark for General Tool Agents. NeurIPS 2024 Dataset &amp; Benchmark Track.<a target="_blank" rel="noopener" href="https://github.com/open-compass/GTA">github</a>​</p>
<p>Qin, Y., et al. (2023). ToolLLM: Facilitating Large Language Models to Master Tool Use. ICLR 2024.<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=dHng2O0Jjr">openreview</a>​</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.14650">https://arxiv.org/abs/2511.14650</a></li>
<li><a target="_blank" rel="noopener" href="https://aclanthology.org/2025.naacl-long.44.pdf">https://aclanthology.org/2025.naacl-long.44.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.01489">https://arxiv.org/abs/2507.01489</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/html/2505.01441v1">https://arxiv.org/html/2505.01441v1</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/html/2510.12838v3">https://arxiv.org/html/2510.12838v3</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/open-compass/GTA">https://github.com/open-compass/GTA</a></li>
<li><a target="_blank" rel="noopener" href="https://symflower.com/en/company/blog/2025/function-calling-llm-agents/">https://symflower.com/en/company/blog/2025/function-calling-llm-agents/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.klavis.ai/blog/function-calling-and-agentic-ai-in-2025-what-the-latest-benchmarks-tell-us-about-model-performance">https://www.klavis.ai/blog/function-calling-and-agentic-ai-in-2025-what-the-latest-benchmarks-tell-us-about-model-performance</a></li>
<li><a target="_blank" rel="noopener" href="https://www.anthropic.com/engineering/multi-agent-research-system">https://www.anthropic.com/engineering/multi-agent-research-system</a></li>
<li><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=dHng2O0Jjr">https://openreview.net/forum?id=dHng2O0Jjr</a></li>
<li><a target="_blank" rel="noopener" href="https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Accenture-TechVision-2025-Full-Report-CN.pdf">https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Accenture-TechVision-2025-Full-Report-CN.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/jingyaogong/minimind">https://github.com/jingyaogong/minimind</a></li>
<li><a target="_blank" rel="noopener" href="https://www.shiyanjia.com/knowledge/articleinfo-8971.html">https://www.shiyanjia.com/knowledge/articleinfo-8971.html</a></li>
<li><a target="_blank" rel="noopener" href="https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Zhan-Wang-2025-Humans-and-AI.pdf">https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Zhan-Wang-2025-Humans-and-AI.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://m.fastbull.com/cn/news-detail/4364993_1">https://m.fastbull.com/cn/news-detail/4364993_1</a></li>
<li><a target="_blank" rel="noopener" href="https://bix-tech.com/the-15-best-ai-agent-tools-in-2025-practical-picks-clear-criteria-and-real-world-use-cases/">https://bix-tech.com/the-15-best-ai-agent-tools-in-2025-practical-picks-clear-criteria-and-real-world-use-cases/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.getdynamiq.ai/post/llm-agents-explained-complete-guide-in-2025">https://www.getdynamiq.ai/post/llm-agents-explained-complete-guide-in-2025</a></li>
<li><a target="_blank" rel="noopener" href="https://www.intuz.com/blog/best-ai-agent-frameworks">https://www.intuz.com/blog/best-ai-agent-frameworks</a></li>
<li><a target="_blank" rel="noopener" href="https://www.lasso.security/blog/agentic-ai-tools">https://www.lasso.security/blog/agentic-ai-tools</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.n8n.io/llm-agents/">https://blog.n8n.io/llm-agents/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.kubiya.ai/blog/ai-agent-orchestration-frameworks">https://www.kubiya.ai/blog/ai-agent-orchestration-frameworks</a></li>
<li><a target="_blank" rel="noopener" href="https://sintra.ai/blog/best-ai-agents-in-2025-top-15-tools-platforms-frameworks">https://sintra.ai/blog/best-ai-agents-in-2025-top-15-tools-platforms-frameworks</a></li>
<li><a target="_blank" rel="noopener" href="https://orq.ai/blog/llm-agents">https://orq.ai/blog/llm-agents</a></li>
<li><a target="_blank" rel="noopener" href="https://www.lyzr.ai/blog/ai-agent-framework/">https://www.lyzr.ai/blog/ai-agent-framework/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.pragmaticcoders.com/blog/top-tools-for-building-ai-agents">https://www.pragmaticcoders.com/blog/top-tools-for-building-ai-agents</a></li>
<li><a target="_blank" rel="noopener" href="https://www.patronus.ai/ai-agent-development/ai-agent-tools">https://www.patronus.ai/ai-agent-development/ai-agent-tools</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.02554">https://arxiv.org/abs/2510.02554</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/html/2506.00886v1">https://arxiv.org/html/2506.00886v1</a></li>
<li><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=jwGPmIqE99">https://openreview.net/forum?id=jwGPmIqE99</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/html/2509.08088v1">https://arxiv.org/html/2509.08088v1</a></li>
<li><a target="_blank" rel="noopener" href="https://sparkco.ai/blog/mastering-langgraph-state-management-in-2025">https://sparkco.ai/blog/mastering-langgraph-state-management-in-2025</a></li>
<li><a target="_blank" rel="noopener" href="https://datatalks.club/blog/open-source-free-ai-agent-evaluation-tools.html">https://datatalks.club/blog/open-source-free-ai-agent-evaluation-tools.html</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/html/2505.21577v3">https://arxiv.org/html/2505.21577v3</a></li>
<li><a target="_blank" rel="noopener" href="https://www.digitalapplied.com/blog/langchain-ai-agents-guide-2025">https://www.digitalapplied.com/blog/langchain-ai-agents-guide-2025</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.scottlogic.com/2025/10/27/testing-open-source-llms.html">https://blog.scottlogic.com/2025/10/27/testing-open-source-llms.html</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/html/2507.18901v1">https://arxiv.org/html/2507.18901v1</a></li>
<li><a target="_blank" rel="noopener" href="https://www.langchain.com/state-of-agent-engineering">https://www.langchain.com/state-of-agent-engineering</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/html/2512.13059v1">https://arxiv.org/html/2512.13059v1</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/papers/2307.16789">https://huggingface.co/papers/2307.16789</a></li>
<li><a target="_blank" rel="noopener" href="https://thesequence.substack.com/p/the-sequence-knowledge-532-understanding">https://thesequence.substack.com/p/the-sequence-knowledge-532-understanding</a></li>
<li><a target="_blank" rel="noopener" href="https://sparkco.ai/blog/deep-dive-into-tool-selection-algorithms-for-2025">https://sparkco.ai/blog/deep-dive-into-tool-selection-algorithms-for-2025</a></li>
<li><a target="_blank" rel="noopener" href="https://www.getmaxim.ai/articles/top-5-ai-evaluation-tools-in-2025-comprehensive-comparison-for-production-ready-llm-and-agentic-systems/">https://www.getmaxim.ai/articles/top-5-ai-evaluation-tools-in-2025-comprehensive-comparison-for-production-ready-llm-and-agentic-systems/</a></li>
<li><a target="_blank" rel="noopener" href="https://iclr.cc/virtual/2024/poster/18267">https://iclr.cc/virtual/2024/poster/18267</a></li>
<li><a target="_blank" rel="noopener" href="https://www.confident-ai.com/blog/greatest-llm-evaluation-tools-in-2025">https://www.confident-ai.com/blog/greatest-llm-evaluation-tools-in-2025</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/OpenBMB/ToolBench">https://github.com/OpenBMB/ToolBench</a></li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://gaoguodong03.github.io/gdBlog">GuoDong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://gaoguodong03.github.io/gdBlog/2026/01/13/%E5%B7%A5%E5%85%B7%E9%80%89%E5%8F%96/">https://gaoguodong03.github.io/gdBlog/2026/01/13/%E5%B7%A5%E5%85%B7%E9%80%89%E5%8F%96/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://gaoguodong03.github.io/gdBlog" target="_blank">果冻小配方</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/gdBlog/tags/%E8%B0%83%E7%A0%94/">调研</a><a class="post-meta__tags" href="/gdBlog/tags/LLM/">LLM</a><a class="post-meta__tags" href="/gdBlog/tags/Agent/">Agent</a><a class="post-meta__tags" href="/gdBlog/tags/%E6%9E%B6%E6%9E%84/">架构</a><a class="post-meta__tags" href="/gdBlog/tags/ToolSection/">ToolSection</a></div><div class="post-share"><div class="social-share" data-image="/gdBlog/./img/logoLLM.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/gdBlog/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="/gdBlog/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/gdBlog/2026/01/13/AGI-NEXT-%E5%B3%B0%E4%BC%9A/" title="AGI-NEXT 峰会"><img class="cover" src="/gdBlog/./img/logoLLM.png" onerror="onerror=null;src='/gdBlog/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">AGI-NEXT 峰会</div></div><div class="info-2"><div class="info-item-1">Q1: 为什么说Chat时代已经结束？ 经过一年的观察，唐杰认为单纯做Chat已经不是在真正解决问题。他原本预判大模型会替代搜索，但现实是谷歌反而用AI把自己的搜索革命了。而2025年初DeepSeek的出现，在他看来彻底终结了Chat范式的竞争。 “可能对研究界、产业界，甚至对很多人都是’横空出世’。”唐杰说，“在DeepSeek这种范式下，Chat时代基本上算是解决了。我们做得再好，也许跟DeepSeek差不多，或许在上面再个性化一点、变成有情感的Chat。但总的来讲，这个范式基本到头了，剩下更多是工程和技术问题。” 这个判断促使智谱做出战略转向。团队内部争论了很多个晚上，最终决定把所有精力放在Coding和Agent上。2025年7月，智谱发布4.5版本，把Coding、Agentic、Reasoning能力整合在一起。 但真实世界的反馈很快给了他们一记重击。 用户拿着模型去编”植物大战僵尸”，结果编不出来。”真实编程环境下有大量问题需要解决。”唐杰说。团队通过RLVR（可验证强化学习）配合编程环境作为反馈，才把效果提升上去。这个经历让他意识到：跑分是跑分，真正让能力进入主...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/gdBlog/2026/01/13/AGI-NEXT-%E5%B3%B0%E4%BC%9A/" title="AGI-NEXT 峰会"><img class="cover" src="/gdBlog/./img/logoLLM.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-13</div><div class="info-item-2">AGI-NEXT 峰会</div></div><div class="info-2"><div class="info-item-1">Q1: 为什么说Chat时代已经结束？ 经过一年的观察，唐杰认为单纯做Chat已经不是在真正解决问题。他原本预判大模型会替代搜索，但现实是谷歌反而用AI把自己的搜索革命了。而2025年初DeepSeek的出现，在他看来彻底终结了Chat范式的竞争。 “可能对研究界、产业界，甚至对很多人都是’横空出世’。”唐杰说，“在DeepSeek这种范式下，Chat时代基本上算是解决了。我们做得再好，也许跟DeepSeek差不多，或许在上面再个性化一点、变成有情感的Chat。但总的来讲，这个范式基本到头了，剩下更多是工程和技术问题。” 这个判断促使智谱做出战略转向。团队内部争论了很多个晚上，最终决定把所有精力放在Coding和Agent上。2025年7月，智谱发布4.5版本，把Coding、Agentic、Reasoning能力整合在一起。 但真实世界的反馈很快给了他们一记重击。 用户拿着模型去编”植物大战僵尸”，结果编不出来。”真实编程环境下有大量问题需要解决。”唐杰说。团队通过RLVR（可验证强化学习）配合编程环境作为反馈，才把效果提升上去。这个经历让他意识到：跑分是跑分，真正让能力进入主...</div></div></div></a><a class="pagination-related" href="/gdBlog/2025/10/11/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E5%90%8C%E6%9E%B6%E6%9E%84%E8%B0%83%E7%A0%94/" title="多智能体协同架构调研"><img class="cover" src="/gdBlog/./img/logoZiyouzhiyi.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-11</div><div class="info-item-2">多智能体协同架构调研</div></div><div class="info-2"><div class="info-item-1">上下文工程 任务管理者 依次往总线扔任务 会议时间文档链接：https://free4inno.feishu.cn/wiki/CxV0wuVATi8Z0hk6wF8cWgzCnTb报告时间：2025&#x2F;10&#x2F;10报告人：孟千斌 简要记录调研了多种多智能体协同架构，包括 OpenManus、微软开源的 AutoGen、字节开源的 LongManus（基于 LongGraph）等，并对它们进行了横向对比  OpenManus：因闭源，分析基于官网 Blog 及演示视频，聚焦其多智能体协同模式，单智能体模式未涉及。 AutoGen：提供 5 种多智能体协同解法： 双智能体聊天（带函数调用）：由用户代理和助手构成，通过交替对话、任务拆分函数调用逐步完成任务，支持人工在关键节点介入。 群聊（Group chat）：预设多角色智能体与群聊管理器，管理器根据上下文和角色能力自动路由任务，公共历史记录信息，支持发布 &#x2F; 订阅模式优化。 AutoBuild：能从自然语言需求出发，自动生成带角色定位的智能体并组成群聊，经协作完成任务后反思总结并返回结果。 Mixture ...</div></div></div></a><a class="pagination-related" href="/gdBlog/2026/01/02/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%AF%94%E8%BE%83/" title="大型语言模型架构比较"><img class="cover" src="/gdBlog/./img/logoLLM.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-02</div><div class="info-item-2">大型语言模型架构比较</div></div><div class="info-2"><div class="info-item-1">写在前面文章链接：从 DeepSeek V3 到 Mistral 3 Large：现代大型语言模型架构设计解析 [[2025年大型语言模型现状：进展、问题与预测]] 自最初的 GPT 架构开发以来，已经过去七年。乍一看，回顾 GPT-2（2019 年）以及 DeepSeek V3 和 Llama 4（2024-2025 年），你可能会惊讶于这些模型在结构上依然如此相似。当然，位置嵌入已经从绝对嵌入演变为旋转嵌入（RoPE），多头注意力基本被分组查询注意力取代，更高效的 SwiGLU 取代了像 GELU 这样的激活函数。但在这些细微的改进背后，我们真的见证了突破性的变革，还是仅仅在打磨相同的架构基础？ 比较大型语言模型以确定其表现良好（或不佳）的关键因素，向来具有挑战性：数据集、训练技术和超参数差异巨大，且通常缺乏充分的文档。不过，我认为审视架构本身的结构变化，对于了解 2025 年 LLM 开发者的动态，仍然有很大价值。（其中一部分见下图 1。）因此，在本文中，我将不讨论基准性能或训练算法，而是聚焦于定义当今旗舰开放模型的架构发展。 ![[ObsidianPicture&#x2F...</div></div></div></a><a class="pagination-related" href="/gdBlog/2026/01/12/%E8%AE%B0%E5%BF%86%EF%BC%8C%E4%B8%8A%E4%B8%8B%E6%96%87%EF%BC%8C%E8%A7%84%E5%88%92%EF%BC%8C%E9%80%89%E5%8F%96%E7%8E%B0%E7%8A%B6/" title="智能体四模块现状"><img class="cover" src="/gdBlog/./img/logoZiyouzhiyi.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-12</div><div class="info-item-2">智能体四模块现状</div></div><div class="info-2"><div class="info-item-1">1. 记忆 (Memory): 从被动存储到主动学习智能体的记忆模块负责信息的持久化存储和高效检索，解决了大型语言模型（LLM）本身“无状态”、“健忘”的核心问题。  早期状态 (2023-2024): 主要依赖RAG (Retrieval-Augmented Generation)。通过将外部知识（文档、数据库）转换为向量，并存储在向量数据库（如Pinecone, Chroma）中。当用户提问时，系统检索最相关的文本片段，并将其作为“短期记忆”喂给LLM。这是一种相对被动的“开卷考试”。  最新进展 (2025-2026):  主动记忆管理 (Active Memory Curation): Agent不再只是被动检索。它能够自主决定什么信息值得被记住、什么信息应该被遗忘或归档。例如，在一次复杂的任务后，Agent 会生成一个“任务总结”或“经验教训”，并将其结构化地存入长期记忆中，而不是存储原始的、冗长的对话记录。 分层与混合记忆 (Hierarchical &amp; Hybrid Memory): Agent的记忆系统变得更加复杂，模拟人脑结构。 感觉记忆 (Sensor...</div></div></div></a><a class="pagination-related" href="/gdBlog/2026/01/02/2025%E5%B9%B4%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%8E%B0%E7%8A%B6%EF%BC%9A%E8%BF%9B%E5%B1%95%E3%80%81%E9%97%AE%E9%A2%98%E4%B8%8E%E9%A2%84%E6%B5%8B/" title="2025年大型语言模型现状：进展、问题与预测"><img class="cover" src="/gdBlog/./img/logoLLM.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-02</div><div class="info-item-2">2025年大型语言模型现状：进展、问题与预测</div></div><div class="info-2"><div class="info-item-1">原文链接 随着2025年即将结束，我想回顾今年大型语言模型中一些最重要的发展，反思那些仍然存在的局限性和未解决的问题，并分享一些对未来可能出现的展望。 1. 推理之年、RLVR 和 GRPO缩放依然有效，但实际上并没有改变大型语言模型的行为或实际体验（唯一的例外是 OpenAI 新发布的 o1，它增加了推理痕迹）。因此，当 DeepSeek 在 2025 年 1 月发布他们的 R1 论文 ，证明通过强化学习可以发展类推理行为时，这成为了一件大事。（在大型语言模型（LLM）中，推理意味着模型解释其答案，而这种解释本身通常会提高答案的准确性。） 1.1 The DeepSeek MomentDeepSeek R1 因多种原因备受关注： 首先，DeepSeek R1 作为一个开权重模型发布，表现非常好，可与当时最好的专有模型（ChatGPT、Gemini 等）相媲美。 其次，DeepSeek R1 论文促使许多人，尤其是投资者和记者，重新审视了 2024 年 12 月的 DeepSeek V3 早期论文 。这导致了一个修正的结论：虽然训练最先进的模型仍然昂贵，但可能比之前假设便宜一个数...</div></div></div></a><a class="pagination-related" href="/gdBlog/2026/01/12/A2UI/" title="A2UI(Agent to User Interface)"><img class="cover" src="/gdBlog/./img/logoLLM.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-12</div><div class="info-item-2">A2UI(Agent to User Interface)</div></div><div class="info-2"><div class="info-item-1">背景现有AI交互模式的局限性  低效对话交互：用户需通过多轮文本对话完成简单任务（如订餐厅需反复确认时间、人数等细节），效率”低的像蜗牛爬”。  生成式UI技术缺陷：以Copilot Kit为代表的方案存在前端依赖过重问题，AI仅作为”提线木偶”，无法自主定义界面结构。  行业标准碎片化：动态性、安全性、跨平台适配等关键问题缺乏统一解决方案，导致”各搞各的，标准不统一，像一盘散沙”。   A2UI协议核心架构定义与核心理念A2UI（Agent to User Interface）是Google提出的AI界面描述协议，指的是 智能体到用户界面 的无缝集成框架。它代表了一种新的AI交互范式，将大型语言模型&#x2F;智能体与实际用户界面直接连接，实现AI驱动的自动化交互。 12345678┌────────────────────┐    ┌────────────────────┐    ┌────────────────────┐│   AI智能体/LLM     │ →  │    A2UI框架层       │ →  │  应用UI/操作系统   ││  (如GPT、Clau...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/gdBlog/img/touxiang.jpg" onerror="this.onerror=null;this.src='/gdBlog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">GuoDong</div><div class="author-info-description">碎碎念念 岁岁年年</div><div class="site-data"><a href="/gdBlog/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/gdBlog/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/gdBlog/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://www.douyin.com/" target="_blank" title="douyin"><i class="fab fa-tiktok" style="color: #24292e;"></i></a><a class="social-icon" href="https://www.bilibili.com/" target="_blank" title="bilibili"><i class="fab fa-bilibili" style="color: #24292e;"></i></a><a class="social-icon" href="https://github.com/gaoguodong03" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://leetcode.cn/studyplan/top-100-liked/" target="_blank" title="LeetCode"><i class="fab fa-comments" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">南京北京 反复横跳</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-AutoTool-%E9%AB%98%E6%95%88%E5%B7%A5%E5%85%B7%E9%80%89%E6%8B%A9%E6%A1%86%E6%9E%B6%EF%BC%882025%E5%B9%B411%E6%9C%88%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">1. AutoTool: 高效工具选择框架（2025年11月）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%BF%9B%E5%BA%A6%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">实验进度：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AC%E6%AC%A1%E4%BC%9A%E8%AF%9D%E6%80%BB%E7%BB%93"><span class="toc-number">2.1.</span> <span class="toc-text">本次会话总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BF%AE%E5%A4%8D%E4%BA%86%E5%A4%9A%E4%B8%AA%E4%BB%A3%E7%A0%81%E9%97%AE%E9%A2%98"><span class="toc-number">2.2.</span> <span class="toc-text">2. 修复了多个代码问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%A7%A3%E5%86%B3%E4%BA%86%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98"><span class="toc-number">2.3.</span> <span class="toc-text">3. 解决了环境配置问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E4%BC%98%E5%8C%96%E4%BA%86%E9%85%8D%E7%BD%AE"><span class="toc-number">2.4.</span> <span class="toc-text">4. 优化了配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-EASYTOOL-%E7%BB%9F%E4%B8%80%E5%B7%A5%E5%85%B7%E6%8C%87%E4%BB%A4%E6%A1%86%E6%9E%B6%EF%BC%882025%E5%B9%B44%E6%9C%88%EF%BC%8CNAACL%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">2. EASYTOOL: 统一工具指令框架（2025年4月，NAACL）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Agent-as-Tool-%E5%88%86%E5%B1%82%E5%86%B3%E7%AD%96%E6%A1%86%E6%9E%B6%EF%BC%882025%E5%B9%B47%E6%9C%88%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">3. Agent-as-Tool: 分层决策框架（2025年7月）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-ARTIST-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%B7%A5%E5%85%B7%E9%9B%86%E6%88%90%E6%A1%86%E6%9E%B6%EF%BC%882024%E5%B9%B45%E6%9C%88%EF%BC%89"><span class="toc-number">5.</span> <span class="toc-text">4. ARTIST: 强化学习与工具集成框架（2024年5月）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-A%C2%B2FM-%E8%87%AA%E9%80%82%E5%BA%94%E5%A4%9A%E6%A8%A1%E5%BC%8F%E4%BB%A3%E7%90%86%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B%EF%BC%882025%E5%B9%B410%E6%9C%88%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">5. A²FM: 自适应多模式代理基础模型（2025年10月）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E7%82%B9%E5%9F%BA%E5%87%86%E5%92%8C%E8%AF%84%E4%BC%B0%E6%A1%86%E6%9E%B6"><span class="toc-number">7.</span> <span class="toc-text">重点基准和评估框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GTA-%E9%80%9A%E7%94%A8%E5%B7%A5%E5%85%B7%E6%99%BA%E8%83%BD%E4%BD%93%E5%9F%BA%E5%87%86%EF%BC%88NeurIPS-2024%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">GTA: 通用工具智能体基准（NeurIPS 2024）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%AF%E5%85%8B%E5%88%A9%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%8E%92%E8%A1%8C%E6%A6%9C%EF%BC%88BFCL%EF%BC%89"><span class="toc-number">9.</span> <span class="toc-text">伯克利函数调用排行榜（BFCL）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MCPMark-%E5%9F%BA%E5%87%86%EF%BC%88Model-Context-Protocol%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">MCPMark 基准（Model Context Protocol）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E7%82%B9%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%92%8C%E5%8F%AF%E5%A4%8D%E7%8E%B0%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">11.</span> <span class="toc-text">重点开源项目和可复现的实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-RepoMaster%EF%BC%9A%E5%AD%98%E5%82%A8%E5%BA%93%E8%87%AA%E4%B8%BB%E6%8E%A2%E7%B4%A2%E6%A1%86%E6%9E%B6"><span class="toc-number">12.</span> <span class="toc-text">1. RepoMaster：存储库自主探索框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-EnvX%EF%BC%9A%E5%AD%98%E5%82%A8%E5%BA%93%E6%99%BA%E8%83%BD%E4%BD%93%E5%8C%96%E6%A1%86%E6%9E%B6"><span class="toc-number">13.</span> <span class="toc-text">2. EnvX：存储库智能体化框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-LangGraph-LangChain%EF%BC%88%E7%94%9F%E4%BA%A7%E7%BA%A7%E6%A1%86%E6%9E%B6%EF%BC%8C2025%E5%B9%B4%EF%BC%89"><span class="toc-number">14.</span> <span class="toc-text">3. LangGraph + LangChain（生产级框架，2025年）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Anthropic-%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%A0%94%E7%A9%B6%E7%B3%BB%E7%BB%9F%EF%BC%882025%E5%B9%B46%E6%9C%88%EF%BC%89"><span class="toc-number">15.</span> <span class="toc-text">4. Anthropic 多智能体研究系统（2025年6月）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-ToolBench-%E5%92%8C-ToolLLaMA%EF%BC%882023-2025%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89"><span class="toc-number">16.</span> <span class="toc-text">5. ToolBench 和 ToolLLaMA（2023-2025持续更新）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%A5%E5%85%B7%E9%80%89%E6%8B%A9%E4%B8%AD%E7%9A%84%E6%9C%80%E6%96%B0%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF"><span class="toc-number">17.</span> <span class="toc-text">工具选择中的最新技术趋势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%95%88%E7%8E%87%E4%BC%98%E5%8C%96%E7%9A%84%E7%BB%9F%E8%AE%A1%E7%BB%93%E6%9E%84%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-number">18.</span> <span class="toc-text">1. 效率优化的统计结构化方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%A4%9A%E5%B1%82%E4%BF%A1%E6%81%AF%E5%89%AA%E6%9E%9D"><span class="toc-number">19.</span> <span class="toc-text">2. 多层信息剪枝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E7%9F%A5%E8%AF%86%E5%9B%BE%E9%A9%B1%E5%8A%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E5%AF%BC%E8%88%AA"><span class="toc-number">20.</span> <span class="toc-text">3. 知识图驱动的工具导航</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%88%86%E5%B1%82%E4%B8%8E%E8%A7%A3%E8%80%A6%E6%9E%B6%E6%9E%84"><span class="toc-number">21.</span> <span class="toc-text">4. 分层与解耦架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E8%87%AA%E9%80%82%E5%BA%94%E6%A8%A1%E5%BC%8F%E9%80%89%E6%8B%A9"><span class="toc-number">22.</span> <span class="toc-text">5. 自适应模式选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E5%BB%BA%E8%AE%AE%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="toc-number">23.</span> <span class="toc-text">总体建议与最佳实践</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E6%9C%AF%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91"><span class="toc-number">24.</span> <span class="toc-text">学术研究方向</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E8%B7%B5%E9%83%A8%E7%BD%B2%E5%BB%BA%E8%AE%AE"><span class="toc-number">25.</span> <span class="toc-text">实践部署建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9C%9F%E5%AE%9E%E6%80%A7%E5%A3%B0%E6%98%8E"><span class="toc-number">26.</span> <span class="toc-text">数据真实性声明</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">27.</span> <span class="toc-text">关键参考文献</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/gdBlog/2026/01/13/AGI-NEXT-%E5%B3%B0%E4%BC%9A/" title="AGI-NEXT 峰会">AGI-NEXT 峰会</a><time datetime="2026-01-12T16:00:00.000Z" title="发表于 2026-01-13 00:00:00">2026-01-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/gdBlog/2026/01/13/%E5%B7%A5%E5%85%B7%E9%80%89%E5%8F%96/" title="工具选取">工具选取</a><time datetime="2026-01-12T16:00:00.000Z" title="发表于 2026-01-13 00:00:00">2026-01-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/gdBlog/2026/01/12/A2UI/" title="A2UI(Agent to User Interface)">A2UI(Agent to User Interface)</a><time datetime="2026-01-11T16:00:00.000Z" title="发表于 2026-01-12 00:00:00">2026-01-12</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div class="footer-other"><div class="footer-copyright"></div><div class="footer_custom_text"><style>
  .footer {
    text-align: center;
    position: relative;
  }
  .social-links {
    display: flex;
    justify-content: center;
    gap: 1.5rem;
    flex-wrap: wrap;
  }
  .social-links i {
    color: #000000;
  }
  .social-link {
    color: #000000;
    font-size: 1.2rem;
    transition: all 0.3s ease;
    display: inline-flex;
    align-items: center;
    justify-content: center;
    width: 2.5rem;
    height: 2.5rem;
    border-radius: 50%;
    background: rgba(0, 0, 0, 0.1);
  }
  .social-link:hover {
    color: #333333;
    background: rgba(0, 0, 0, 0.2);
    transform: translateY(-3px) scale(1.2);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
    text-decoration: none !important; 
  }
  .footer p {
    margin: 0.5rem 0;
    line-height: 1;
  }
  .copyright {
    font-size: 1.1rem; 
    color: #000000;
    font-weight: 400;
  }
  .tagline {
    font-size: 0.8rem;
    color: #333333;
    font-style: italic;
    font-weight: 500;
  }
  .visitor-count {
    font-size: 0.75rem;
    color: rgba(0, 0, 0, 0.7);
    font-weight: 300;
  }
  #visitorCount {
    font-weight: bold;
  }
</style>
<div class="footer">
  <p class="copyright">© 2025 果冻小配方 - 所有权利保留</p>
  <p class="tagline">> 碎碎念念 岁岁年年 <</p>
  <p class="visitor-count">访问量: <span id="visitorCount">1024</span> | 你是第 <span id="dailyVisitor">1</span> 位今日访客</p>
</div>
<script>
  // 确保DOM加载完成后执行
  document.addEventListener('DOMContentLoaded', function() {
    // 模拟访问量增长
    function updateVisitorCount() {
      const countElement = document.getElementById('visitorCount');
      let count = parseInt(countElement.textContent) || 1024;
      // 从localStorage获取或初始化计数
      const storedCount = localStorage.getItem('totalVisitors');
      if (storedCount) {
        count = parseInt(storedCount);
        countElement.textContent = count;
      }
      // 每日访客计数
      const today = new Date().toDateString();
      const dailyData = JSON.parse(localStorage.getItem('dailyVisitors') || '{"date":"", "count":0}');
      if (dailyData.date !== today) {
        dailyData.date = today;
        dailyData.count = 0;
      }
      dailyData.count += 1;
      document.getElementById('dailyVisitor').textContent = dailyData.count;
      localStorage.setItem('dailyVisitors', JSON.stringify(dailyData));
      // 每30秒随机增加访问量
      setInterval(() => {
        count += Math.floor(Math.random() * 3);
        countElement.textContent = count;
        localStorage.setItem('totalVisitors', count.toString());
      }, 30000);
    }
    updateVisitorCount();
    // 添加点击动画效果
    const socialLinks = document.querySelectorAll('.social-link');
    socialLinks.forEach(link => {
      link.addEventListener('click', function() {
        this.style.transform = 'scale(0.9)';
        setTimeout(() => {
          this.style.transform = '';
        }, 300);
      });
    });
  });
</script>
</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/gdBlog/js/utils.js"></script><script src="/gdBlog/js/main.js"></script><div class="js-pjax"></div><script src="/config/js/happy-title.js" async></script><script src="/config/js/foot.js" async></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_categories_card_injector_config(){
    // 检查容器是否存在
    var parent_div_git = document.getElementById('recent-posts');
    // 如果容器不存在，则动态创建
    if (!parent_div_git) {
      console.warn('butterfly_categories_card: 挂载容器不存在，正在动态创建...');
      // 创建新容器（默认插入到页面主体顶部）
      parent_div_git = document.createElement('div');
      parent_div_git.id = 'recent-posts'; // 赋予配置的ID
      document.querySelector('#page').prepend(parent_div_git); // 插入到 #content-inner 内
    }
    var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 950px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 800px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(/img/logo.jpg);"> <a class="categoryBar-list-link" href="/categories/果冻的日记本/">果冻的日记本</a><span class="categoryBar-list-count">4</span><span class="categoryBar-list-descr">果冻的航海日记</span></li><li class="categoryBar-list-item" style="background:url(/img/logo.jpg);"> <a class="categoryBar-list-link" href="/categories/果冻的理论学习/">果冻的理论学习</a><span class="categoryBar-list-count">14</span><span class="categoryBar-list-descr">Hexo</span></li><li class="categoryBar-list-item" style="background:url(/img/logo.jpg);"> <a class="categoryBar-list-link" href="/categories/果冻的科普专区/">果冻的科普专区</a><span class="categoryBar-list-count">7</span><span class="categoryBar-list-descr">果冻的奇妙小工具</span></li><li class="categoryBar-list-item" style="background:url(/img/logo.jpg);"> <a class="categoryBar-list-link" href="/categories/果冻的奇妙小工具/">果冻的奇妙小工具</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr">果冻的日记本</span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" href="/categories/果冻的航海日志/">果冻的航海日志</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" href="/categories/Hexo/">Hexo</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" href="/categories/果冻的LeetCode刷题/">果冻的LeetCode刷题</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr"></span></li></ul></div></div>';
    console.log('已挂载 butterfly_categories_card');
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
  }
  // 路径匹配逻辑（使用 startsWith）
  if (location.pathname.startsWith('/categories/') || '/categories/' === 'all') {
    butterfly_categories_card_injector_config();
  }
  </script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '300ms');
    arr[i].setAttribute('data-wow-delay', '0ms');
    arr[i].setAttribute('data-wow-offset', '0');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>