[{"title":"JSON","url":"/gdBlog/2025/09/30/JSON/","content":"JSON是一种文本数据格式!\njson和xml之间一般可以转换json文本实际上是一条字符串json的四种类型不允许嵌套,字符串,数值,布尔,null(你也没法嵌套)两种可以嵌套:哈希值:「“字符串”:剩下六种随便,“”:“”」最后一个键值对后不能加“,”数组:[],用“,”隔开,最后一个不加,六种随便一种,不用统一类型\n空格和换行无所谓\n一般数据量不大,大了的话一般用xml,比较方便.\n","categories":["果冻的航海日志"],"tags":["tools"]},{"title":"Docker","url":"/gdBlog/2025/09/30/Docker/","content":"远程镜像仓库本地镜像(镜像是只读的)本地仓库\n镜像版本tag版本是完全独立的,last是最新的docker pull&#x2F;push 镜像名docker images 查看本地镜像docker search\n容器真正的示例,隔离网络,文件.不同容器可能会争抢资源1容器打包成镜像,再上传到仓库docker psdocker ps -adocekr start&#x2F;stop&#x2F;rm IDdocker commit -a “作者名称” -m “log信息” ID 打包成镜像docker cp 文件目录 容器ID:目标目录   从前拷贝到后docker exec -it ID &#x2F;bin&#x2F;bash  进入容器内部\ndickerfile脚本 是可以通过下载文件的一些来创建脚本\n网络中的映射一般是端口映射,容器端口8001映射到宿主机的8080\n","categories":["果冻的航海日志"],"tags":["tools"]},{"title":"MCP(Model Context Protocol模型上下文协议)","url":"/gdBlog/2025/09/30/MCP/","content":"MCP 起源于 2024 年 11 月 25 日, 定义了应用程序和 AI 模型之间交换上下文信息的方式。这使得开发者能够以一致的方式将各种数据源、工具和功能连接到 AI 模型（一个中间协议层），就像 USB-C 让不同设备能够通过相同的接口连接一样。MCP 的目标是创建一个通用标准，使 AI 应用程序的开发和集成变得更加简单和统一。\n起源思考我认为 MCP 的出现是 prompt engineering 发展的产物。更结构化的上下文信息对模型的 performance 提升是显著的。在构造 prompt 时，希望能提供一些更 specific 的信息（比如本地文件，数据库，一些网络实时信息等）给模型，这样模型更容易理解真实场景中的问题。\n第一阶段手工输入. 想象一下没有 MCP 之前我们会怎么做？我们可能会人工从数据库中筛选或者使用工具检索可能需要的信息，手动的粘贴到 prompt 中。随着我们要解决的问题越来越复杂，手工把信息引入到 prompt 中会变得越来越困难。\n第二阶段 function call. 为了克服手工 prompt 的局限性，许多 LLM 平台（如 OpenAI、Google）引入了 function call 功能。这一机制允许模型在需要时调用预定义的函数来获取数据或执行操作。但是 function call 依赖平台, 不同 LLM 平台的 function call API 实现差异较大。例如，OpenAI 的函数调用方式与 Google 的不兼容，开发者在切换模型时需要重写代码.\n第三阶段 MCP. 数据与工具本身是客观存在的，只不过我们希望将数据连接到模型的这个环节可以更智能更统一。Anthropic 基于这样的痛点设计了 MCP，充当 AI 模型的”万能转接头”，让 LLM 能轻松的获取数据或者调用工具.\n原理先说过程:用户在 Claude 客户端（如 Claude Desktop、Cursor）输入问题后，客户端会先将问题发送给 Claude 大模型；Claude 接收问题后，会分析当前可用的工具（如文档解析、数据查询等）并确定需调用的工具类型及数量；接着客户端通过 MCP Server（模型上下文协议服务端），以标准化方式执行 Claude 选定的工具；工具执行完成后，其处理结果会通过 MCP 回传给 Claude；Claude 再结合用户原始问题与工具执行结果，构建最终的 Prompt 并生成自然语言回应；最后，客户端将这份回应展示给用户，完成整个交互流程。\n关于模型如何选择工具模型是通过 prompt 来确定当前有哪些工具。我们通过将工具的具体使用描述以文本的形式传递给模型，供模型了解有哪些工具以及结合实时情况进行选择。参考代码中的注释：\n... # 省略了无关的代码async def start(self):    # 初始化所有的 mcp server    for server in self.servers:        await server.initialize()​    # 获取所有的 tools 命名为 all_tools    all_tools = []    for server in self.servers:        tools = await server.list_tools()        all_tools.extend(tools)​    # 将所有的 tools 的功能描述格式化成字符串供 LLM 使用    # tool.format_for_llm() 我放到了这段代码最后，方便阅读。    tools_description = &quot;\\n&quot;.join(        [tool.format_for_llm() for tool in all_tools]    )​    # 这里就不简化了，以供参考，实际上就是基于 prompt 和当前所有工具的信息    # 询问 LLM（Claude） 应该使用哪些工具。    system_message = (        &quot;You are a helpful assistant with access to these tools:\\n\\n&quot;        f&quot;&#123;tools_description&#125;\\n&quot;        &quot;Choose the appropriate tool based on the user&#x27;s question. &quot;        &quot;If no tool is needed, reply directly.\\n\\n&quot;        &quot;IMPORTANT: When you need to use a tool, you must ONLY respond with &quot;        &quot;the exact JSON object format below, nothing else:\\n&quot;        &quot;&#123;\\n&quot;        &#x27;    &quot;tool&quot;: &quot;tool-name&quot;,\\n&#x27;        &#x27;    &quot;arguments&quot;: &#123;\\n&#x27;        &#x27;        &quot;argument-name&quot;: &quot;value&quot;\\n&#x27;        &quot;    &#125;\\n&quot;        &quot;&#125;\\n\\n&quot;        &quot;After receiving a tool&#x27;s response:\\n&quot;        &quot;1. Transform the raw data into a natural, conversational response\\n&quot;        &quot;2. Keep responses concise but informative\\n&quot;        &quot;3. Focus on the most relevant information\\n&quot;        &quot;4. Use appropriate context from the user&#x27;s question\\n&quot;        &quot;5. Avoid simply repeating the raw data\\n\\n&quot;        &quot;Please use only the tools that are explicitly defined above.&quot;    )    messages = [&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_message&#125;]​    while True:        # Final... 假设这里已经处理了用户消息输入.        messages.append(&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;)​        # 将 system_message 和用户消息输入一起发送给 LLM        llm_response = self.llm_client.get_response(messages)​    ... # 后面和确定使用哪些工具无关    ​class Tool:    &quot;&quot;&quot;Represents a tool with its properties and formatting.&quot;&quot;&quot;​    def __init__(        self, name: str, description: str, input_schema: dict[str, Any]    ) -&gt; None:        self.name: str = name        self.description: str = description        self.input_schema: dict[str, Any] = input_schema​    # 把工具的名字 / 工具的用途（description）和工具所需要的参数（args_desc）转化为文本    def format_for_llm(self) -&gt; str:        &quot;&quot;&quot;Format tool information for LLM.​        Returns:            A formatted string describing the tool.        &quot;&quot;&quot;        args_desc = []        if &quot;properties&quot; in self.input_schema:            for param_name, param_info in self.input_schema[&quot;properties&quot;].items():                arg_desc = (                    f&quot;- &#123;param_name&#125;: &#123;param_info.get(&#x27;description&#x27;, &#x27;No description&#x27;)&#125;&quot;                )                if param_name in self.input_schema.get(&quot;required&quot;, []):                    arg_desc += &quot; (required)&quot;                args_desc.append(arg_desc)​        return f&quot;&quot;&quot;Tool: &#123;self.name&#125;Description: &#123;self.description&#125;Arguments:&#123;chr(10).join(args_desc)&#125;&quot;&quot;&quot;\n因此 描述工具的文本input_schema是我们要写的.  大部分情况下，当使用装饰器 @mcp.tool() 来装饰函数时，对应的 name 和 description 等其实直接源自用户定义函数的函数名以及函数的 docstring 等。\n@classmethoddef from_function(    cls,    fn: Callable,    name: str | None = None,    description: str | None = None,    context_kwarg: str | None = None,) -&gt; &quot;Tool&quot;:    &quot;&quot;&quot;Create a Tool from a function.&quot;&quot;&quot;    func_name = name or fn.__name__ # 获取函数名​    if func_name == &quot;&lt;lambda&gt;&quot;:        raise ValueError(&quot;You must provide a name for lambda functions&quot;)​    func_doc = description or fn.__doc__ or &quot;&quot; # 获取函数 docstring    is_async = inspect.iscoroutinefunction(fn)        ... # 更多请参考原始代码...\n模型是通过 prompt engineering，即提供所有工具的结构化描述和 few-shot 的 example 来确定该使用哪些工具。\n工具执行与结果反馈机制其实工具的执行就比较简单和直接了。承接上一步，我们把 system prompt（指令与工具调用描述）和用户消息一起发送给模型，然后接收模型的回复。当模型分析用户请求后，它会决定是否需要调用工具：\n\n无需工具时：模型直接生成自然语言回复。\n需要工具时：模型输出结构化 JSON 格式的工具调用请求。\n\n如果回复中包含结构化 JSON 格式的工具调用请求，则客户端会根据这个 json 代码执行对应的工具。具体的实现逻辑都在 process_llm_response 中，代码，逻辑非常简单。\n如果模型执行了 tool call，则工具执行的结果 result 会和 system prompt 和用户消息一起重新发送给模型，请求模型生成最终回复。\n如果 tool call 的 json 代码存在问题或者模型产生了幻觉怎么办呢？通过阅读代码 发现，我们会 skip 掉无效的调用请求。\n","categories":["果冻的航海日志"],"tags":["tools","LLM"]},{"title":"MVC","url":"/gdBlog/2025/09/30/MVC/","content":"简介MVC（Model-View-Controller，模型 - 视图 - 控制器）是一种软件架构设计模式，其核心思想是分离关注点，通过将应用程序划分为三个相互关联但功能独立的组件.\n各组件的具体作用模型（Model）模型是应用程序的数据中心和业务逻辑核心，负责管理应用程序的数据和处理业务规则，是整个应用的 “大脑”。\n主要职责：\n\n存储和管理应用程序的数据（可以是数据库、内存数据结构等）\n实现核心业务逻辑和数据处理规则\n提供数据访问接口（供控制器调用）\n当数据发生变化时，通知相关视图进行更新（观察者模式）\n独立于视图和控制器，不关心数据如何展示和用户如何操作\n\n视图（View）视图是应用程序的用户界面，负责数据的展示和用户交互的呈现，是用户能直接看到和操作的部分\n主要职责：\n\n从模型获取数据并以特定形式展示给用户（如网页、桌面窗口、移动端界面）\n接收用户的界面操作（如点击按钮、输入文本等），但不处理这些操作的业务逻辑\n不直接与模型交互，通过控制器获取需要展示的数据\n一个模型可以对应多个视图（如同一组数据可以用表格、图表、列表等不同形式展示）\n\n控制器（Controller）控制器是模型和视图之间的协调者，负责处理用户输入并协调模型和视图完成相应操作。\n主要职责：\n\n接收并解析用户的输入请求（来自视图）\n根据用户请求调用相应的模型方法处理数据\n决定处理完成后使用哪个视图展示结果\n不处理业务逻辑，也不负责数据展示，仅负责流程控制\n维护模型和视图之间的映射关系\n\nMVC 工作流程\n用户交互：用户通过视图（如点击按钮、提交表单）发起操作请求\n请求传递：视图将用户请求传递给对应的控制器\n业务处理：控制器调用相应的模型方法，处理业务逻辑和数据\n数据更新：模型处理完成后更新数据状态，必要时通知视图\n视图渲染：控制器选择合适的视图，视图从模型获取最新数据并展示给用户\n\n","categories":["果冻的航海日志"]},{"title":"yuanfang","url":"/gdBlog/2025/09/29/%E5%85%83%E8%8A%B3/","content":"分为studio和chat,准确来说,就是只有studio,其中的一些功能可以发布在chat上,chat只是作为和chatGPT对应的一个页面,可以用来进一步的页面优化.\n应用应用作为工作流式的智能体,可以展示具体的页面,通过子任务的顺序执行,并且可以通过前置代码和后置代码以及一些工具也能优化输出格式.可以选择变量的格式,包括codeVar变量,inputVar输入变量,singleSelect单选框,mutipulSeclect多选框还有下拉框.实现了工具的接口和应用的接口解耦合.\n我实现的应用[[接入Gemini大模型]],输入具体的问题,调用Gemini工具,询问Gemini后返回回答[[元芳接入MCP]],根据自然语言输入,自动调用元芳工具中的工具,并将对应参数直接填入工具中\n方法这方面好像是和方法论相关,主要作用应该是在”创建应用“时的智能创建使用的,,这里是添加一些专业知识,使得方法创建有一定依据.也就是和RAG相关,有时间可以问问潇龚师兄.\n工具相当于一个个API接口,有固定的格式,修改url,head,body等,建议学习一下http的具体格式返回的时候返回所有的内容,后续可以在应用中提取需要的内容我的大部分工具都部署在[[虎符]]上\n","categories":["果冻的航海日志"],"tags":["元芳"]},{"title":"元芳接入MCP","url":"/gdBlog/2025/09/30/%E5%85%83%E8%8A%B3%E6%8E%A5%E5%85%A5MCP/","content":"项目特点(写在前面)基于 Flask + MySQL + ChromaDB 的 工具管理系统 ,部署在虎符上,为元芳mcp-client工具提供服务，主要用于管理和搜索各种元芳工具，并集成MCP,向量检索,内含元芳执行器不依赖其他元芳版本只依赖数据库。\n返回接口执行失败\n&#123;    &quot;log&quot;: [        &#123;            &quot;MCP_select_tool_name&quot;: &quot;工具名称&quot;,            &quot;yf_tool_parameters&quot;: &quot;参数&quot;        &#125;    ],    &quot;error&quot;: &quot;错误信息或最终结果&quot;&#125;\n执行成功\n&#123;    &quot;log&quot;: [        &#123;&quot;name&quot;: &quot;工具1&quot;, &quot;description&quot;: &quot;描述1&quot;&#125;,        &#123;&quot;name&quot;: &quot;工具2&quot;, &quot;description&quot;: &quot;描述2&quot;&#125;,        &#123;&quot;name&quot;: &quot;工具3&quot;, &quot;description&quot;: &quot;描述3&quot;&#125;,        &#123;\t        &quot;MCP_select_tool_name&quot;: &quot;实际选择的工具名&quot;, \t        &quot;yf_tool_parameters&quot;: &quot;具体参数&quot;\t    &#125;    ],    &quot;response&quot;: &quot;工具执行的具体结果内容&quot;&#125;\n\n类Flask应用├── CustomEmbeddingFunction (向量嵌入)├── Tool (数据模型)├── ToolCapability (工具管理)│   ├── search_Tool() 向量搜索│   └── get_tool() 工具详情└── API路由    ├── MCPClient (MCP集成)    └── DashScopeClient (大模型交互)\n主要类描述1. CustomEmbeddingFunction 类(出问题找王闯师兄,我只调用API)\n功能 : 处理向量嵌入请求\n作用 : 向嵌入服务发送请求，将文本转换为向量表示\n关键方法 : call() - 处理嵌入请求并返回向量\n\n2. Tool 类（数据库模型）\n功能 : 定义工具数据表结构\n作用 : 映射MySQL数据库中的tools表\n包含字段 : id、name、description、parameters、host、method、url等工具配置信息\n\n3. ToolCapability 类(元芳执行器的调用方式,元芳能用该工具,我就能用)\n功能 : 工具能力管理核心类\n作用 : 管理ChromaDB连接和工具搜索功能\n关键方法 :\ninit() - 初始化数据库连接\nsearch_Tool() - 基于任务描述搜索相关工具\nget_tool() - 从数据库获取工具详情\n\n\n\n4. MCPClient 类（在api_clients.py中）\n功能 : MCP服务器客户端\n作用 : 连接MCP服务器并处理工具调用\n关键方法 : connect_to_server() , process_query()\n\n5. DashScopeClient 类（在api_clients.py中）\n功能 : 通义千文API客户端\n作用 : 与大模型进行对话交互\n关键方法 : chat() - 发送聊天请求\n\n以后的元芳工具描述格式名称:[MCP]_[核心动作][目标对象]描述:\t功能说明：xxxxx\t输入参数：\t- xxx：xxxxxxx\t适用场景：\t- xxxxx\t- xxxxx\t- xxxxx例如:名称:[MCP]查询_虎符运行指标_Prometheus_服务描述:\t功能说明：通过PromQL查询语句，获取获取虎符系统的各类运行指标数据。\t输入参数：\t- query：字符串，符合PromQL语法的Prometheus查询语句。\t适用场景：\t- 监控虎符系统运行状态\t- 排查虎符服务异常\t- 收集性能指标数据\n\n\n工具的接入依靠1）先是向量检索工具数据库中的描述和名称字段，筛选出三个符合的描述；2）将这三个工具开放的接口连同用户的提问直接交给大模型，大模型会自动填充和调用工具，工具执行过程使用的是另一份元芳执行器的执行代码\nQwen的MCP格式final_response&#123;    &quot;status_code&quot;: 200,                    # HTTP状态码    &quot;code&quot;: &quot;Success&quot;,                     # 业务状态码    &quot;message&quot;: &quot;success&quot;,                  # 业务消息    &quot;output&quot;: &#123;                           # 主要输出内容        &quot;choices&quot;: [            &#123;                &quot;message&quot;: &#123;                    &quot;role&quot;: &quot;assistant&quot;,                    &quot;content&quot;: &quot;模型生成的最终回答内容&quot;                &#125;            &#125;        ]    &#125;,    &quot;usage&quot;: &#123;                            # 使用统计        &quot;input_tokens&quot;: 100,        &quot;output_tokens&quot;: 50,        &quot;total_tokens&quot;: 150    &#125;&#125;\n\n项目意义由于MCP完美适配元芳的“应用-工具”模式, 如果使用MCP, 将不用在直接手动设定某个被调用的工具, MCP可以帮助我们选择工具, 并将参数自动填入, 最后将工具的结果变为自然语言, 我们就能很舒服的通过问问题而调用元芳的所有工具.\n项目来历2024年11月,MCP的诞生[[MCP]]2025年4月,丁安然师姐介绍MCP专题2025年5月,我开始尝试将MCP接入元芳,一开始使用OpenAI的模型,最后改为使用Qwen的模型2025年7月,最后将元芳的工具描述补充完毕.2025年9月,放完暑假,修改部分bug后, 最终将MCP上传Githubyuanfang-mcp\n项目进度一开始, 丁安然师姐在介绍MCP的时候直接通过API的调用接入了三个工具, 并手动添加了工具的描述,和元芳的关系不大, 只是作为演示.之后我便被徐老师安排将MCP接入元芳.\n当时对元芳还不太熟悉,再加上代码能力不够,走了很多很多弯路, 写了很多垃圾代码. 最终确定了先画设计图,定义项目结构,最后再进行编程.![[ObsidianPicture&#x2F;Pasted image 20250930180205.png]]\n这里附上我写的流程图(其中的问题已经全部解决了,只用关心流程)\n![[ObsidianPicture&#x2F;Pasted image 20250930180147.png]]虽然,画了图,但是还是写了一坨屎山.主要原因还是不太熟悉元芳和虎符.\n","categories":["果冻的航海日志"],"tags":["LLM","元芳"]},{"title":"元芳接入Gemini大模型","url":"/gdBlog/2025/09/29/%E6%8E%A5%E5%85%A5Gemini%E5%A4%A7%E6%A8%A1%E5%9E%8B/","content":"了解Geminigemini是google的 所以需要注册google对应的账号,由于需要翻墙再加上需要资金往来,所以放弃这条路了最后选择使用国内的代理网站 ,调用了一个 API 接口, 确实挺好用的\n未完待续…\n","tags":["LLM","元芳"]},{"title":"正则表达式","url":"/gdBlog/2025/09/30/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","content":"高级版关键字搜索性能一般,但无所谓不差这点,功能强大,易于维护\n字符集合g[ a o]t&#x3D;get or got[ a-z]就是a到z ; [^b-c ]除了b到c\n* 出现0或更多 {0}+  1 and more. {1}?  0 or 1            {0,1}{3} 3{3,}. 3 and more{3.6}  3 to 6\n^代表开始  $代表结束\n","categories":["果冻的航海日志"],"tags":["tools"]}]