<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>聊聊Deep Search 和Deep Research | 果冻小配方</title><meta name="author" content="GuoDong"><meta name="copyright" content="GuoDong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="2022 年 11 月 30 日，OpenAI 正式发布 ChatGPT 产品，仅两个月后，其月活用户就突破了 1 个亿，成为历史上增长最快的消费类应用之一。一时之间，生成式 AI 技术遍地开花，国内外科技大厂紧锣密鼓纷纷入场，各种大模型和 AI 产品以星火燎原之势涌现出来。 ChatGPT 的发布对传统搜索（如 Google）和问答社区（如 StackOverflow）造成了强烈的冲击。用户对传">
<meta property="og:type" content="article">
<meta property="og:title" content="聊聊Deep Search 和Deep Research">
<meta property="og:url" content="https://gaoguodong03.github.io/gdBlog/2025/10/03/%E8%81%8A%E8%81%8ADeep-Search-%E5%92%8CDeep-Research/index.html">
<meta property="og:site_name" content="果冻小配方">
<meta property="og:description" content="2022 年 11 月 30 日，OpenAI 正式发布 ChatGPT 产品，仅两个月后，其月活用户就突破了 1 个亿，成为历史上增长最快的消费类应用之一。一时之间，生成式 AI 技术遍地开花，国内外科技大厂紧锣密鼓纷纷入场，各种大模型和 AI 产品以星火燎原之势涌现出来。 ChatGPT 的发布对传统搜索（如 Google）和问答社区（如 StackOverflow）造成了强烈的冲击。用户对传">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gaoguodong03.github.io/gdBlog/img/logoDeepsearch.jpg">
<meta property="article:published_time" content="2025-10-02T16:00:00.000Z">
<meta property="article:modified_time" content="2025-10-11T07:13:20.400Z">
<meta property="article:author" content="GuoDong">
<meta property="article:tag" content="DeepSearch">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="RAG">
<meta property="article:tag" content="tools">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gaoguodong03.github.io/gdBlog/img/logoDeepsearch.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "聊聊Deep Search 和Deep Research",
  "url": "https://gaoguodong03.github.io/gdBlog/2025/10/03/%E8%81%8A%E8%81%8ADeep-Search-%E5%92%8CDeep-Research/",
  "image": "https://gaoguodong03.github.io/gdBlog/img/logoDeepsearch.jpg",
  "datePublished": "2025-10-02T16:00:00.000Z",
  "dateModified": "2025-10-11T07:13:20.400Z",
  "author": [
    {
      "@type": "Person",
      "name": "GuoDong",
      "url": "https://gaoguodong03.github.io/gdBlog"
    }
  ]
}</script><link rel="shortcut icon" href="/gdBlog/img/logo.jpg"><link rel="canonical" href="https://gaoguodong03.github.io/gdBlog/2025/10/03/%E8%81%8A%E8%81%8ADeep-Search-%E5%92%8CDeep-Research/index.html"><link rel="preconnect"/><link rel="stylesheet" href="/gdBlog/css/index.css"><link rel="stylesheet" href="/gdBlog/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/gdBlog/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: '/gdBlog/pluginsSrc/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '聊聊Deep Search 和Deep Research',
  isHighlightShrink: true,
  isToc: true,
  pageType: 'post'
}</script><style>#article-container.post-content h1:before, h2:before, h3:before, h4:before, h5:before, h6:before { -webkit-animation: avatar_turn_around 1s linear infinite; -moz-animation: avatar_turn_around 1s linear infinite; -o-animation: avatar_turn_around 1s linear infinite; -ms-animation: avatar_turn_around 1s linear infinite; animation: avatar_turn_around 1s linear infinite; }</style><!-- hexo injector head_end start --><link rel="stylesheet" href="/gdBlog/./css/categorybar.css"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 8.0.0"></head><body><div id="web_bg" style="background-image: url(/gdBlog/img/bg1.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/gdBlog/img/touxiang.jpg" onerror="this.onerror=null;this.src='/gdBlog/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/gdBlog/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/gdBlog/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/gdBlog/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/gdBlog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/link/"><i class="fa-fw fas fa-link"></i><span> 书签</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/gdBlog/./img/logoDeepsearch.jpg);"><nav id="nav"><!-- 左侧博客信息区域--><span id="blog-info"><a class="nav-site-title" href="/gdBlog/"><img class="site-icon" src="/gdBlog/img/logo.jpg" alt="Logo"><span class="site-name">果冻小配方</span></a><a class="nav-page-title" href="/gdBlog/"><span class="site-name">聊聊Deep Search 和Deep Research</span></a></span><!-- 新增的导航菜单容器（居中布局关键）--><div id="nav-menus-container"><!-- 菜单主体部分--><div id="menus"><!-- 搜索按钮--><!-- 菜单项--><div class="menus_items"><div class="menus_item"><a class="site-page" href="/gdBlog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/gdBlog/link/"><i class="fa-fw fas fa-link"></i><span> 书签</span></a></div></div></div><!-- 移动端汉堡菜单按钮（保持原位置）--><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">聊聊Deep Search 和Deep Research</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-10-02T16:00:00.000Z" title="发表于 2025-10-03 00:00:00">2025-10-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-10-11T07:13:20.400Z" title="更新于 2025-10-11 15:13:20">2025-10-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/gdBlog/categories/%E6%9E%9C%E5%86%BB%E7%9A%84%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/">果冻的理论学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">8.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p><a target="_blank" rel="noopener" href="https://openai.com/index/chatgpt/">2022 年 11 月 30 日</a>，OpenAI 正式发布 ChatGPT 产品，仅两个月后，其月活用户就突破了 1 个亿，成为历史上增长最快的消费类应用之一。一时之间，生成式 AI 技术遍地开花，国内外科技大厂紧锣密鼓纷纷入场，各种大模型和 AI 产品以星火燎原之势涌现出来。</p>
<p>ChatGPT 的发布对传统搜索（如 Google）和问答社区（如 StackOverflow）造成了强烈的冲击。用户对传统搜索的不满早已不是秘密，搜索结果中大量的广告和低质的 SEO 内容导致用户体验很差，而 ChatGPT 通过自然语言以对话的方式为用户直接提供答案，省去了用户在海量的搜索页面之间反复跳转和搜集信息的麻烦。谷歌拥有 DeepMind 和 Google Brain 两大顶尖 AI 实验室，原本有机会站在这波生成式 AI 浪潮的最顶端，但是管理层安于现状，不忍放弃广告业务的利润，最终被 ChatGPT 抢占先机。为了应对 ChatGPT 的冲击，谷歌很快开始了反击，公司在内部发布 <strong>红色代码（Red Code）</strong> 预警，进入战备状态，创始人布林甚至亲自下场为聊天机器人 Bard 写代码。</p>
<p>生成式 AI 和传统搜索之间的战争就此拉开了序幕。</p>
<h2 id="AI-搜索"><a href="#AI-搜索" class="headerlink" title="AI + 搜索"></a>AI + 搜索</h2><p>不过很快人们就发现了 ChatGPT 的不足，尽管 ChatGPT 能以简洁的交互给出即时答案，但是它的答案中充斥了大量的事实性错误，幻觉问题和静态知识是大模型天生的两大局限，导致其答案准确性达不到搜索引擎的要求。一开始，大家只是作为谈资一笑了之，但是随着大模型在商业化应用中的落地，人们的抱怨声也就越来越多，在某些场景下，比如医疗建议，错误的回复可能导致灾难性后果。</p>
<p>为了解决这些问题，又一项新技术应运而生，那就是 <strong>RAG（Retrieval-Augmented Generation，检索增强生成）</strong>，通过引入外部信息源，包括搜索引擎、企业私域知识、个人笔记等一切能查询的信息，可以有效的缓解大模型的幻觉问题，在生成答案时还可以标注信息来源以提升可信度。</p>
<p><a target="_blank" rel="noopener" href="https://openai.com/index/introducing-chatgpt-search/">2024 年 10 月</a>，ChatGPT 推出搜索功能, 国内外产商也纷纷跟进，比如 <a target="_blank" rel="noopener" href="https://chat.deepseek.com/">DeepSeek</a> 的. 如今 <strong>AI + 搜索</strong> 已经是各家大模型产品的标配。</p>
<p>与此同时，<strong>搜索 + AI</strong> 也不甘示弱，比如 Google 面向美国用户推出的 <a target="_blank" rel="noopener" href="https://blog.google/products/search/ai-overviews-search-october-2024/">AI Overviews</a> 功能，在搜索结果顶部提供自然语言生成的答案摘要；百度在搜索顶部也加入了 AI+ 功能.</p>
<p>还有一些比较小众的搜索服务和开源项目，比如 <a target="_blank" rel="noopener" href="https://you.com/">YOU.COM</a>、<a target="_blank" rel="noopener" href="https://iask.ai/">iAsk</a>、<a target="_blank" rel="noopener" href="https://search.lepton.run/">Lepton Search</a> 等，感兴趣的也可以尝试下</p>
<h3 id="技术原理"><a href="#技术原理" class="headerlink" title="技术原理"></a>技术原理</h3><p><strong>AI + 搜索</strong> 的本质是 <strong>朴素 RAG</strong>，我曾在 <a target="_blank" rel="noopener" href="https://www.aneasystone.com/archives/2023/07/doc-qa-using-embedding.html">使用 Embedding 技术打造本地知识库助手</a> 这篇笔记中简单介绍过 RAG 的基本流程，如下图所示：<br>![[ObsidianPicture&#x2F;Pasted image 20251002220318.png]]<br>可以看出它的实现非常简单，唯一的难点是知识库文档和用户问题的向量化以及向量检索，而 <strong>AI + 搜索</strong> 则更简单，直接拿着用户问题去调搜索引擎的接口就行了.</p>
<p>关于如何组织搜索结果和用户问题，可以参考 <a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-R1#official-prompts">DeepSeek 公开的 Prompt</a>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">search_answer_zh_template = \</span><br><span class="line">&#x27;&#x27;&#x27;# 以下内容是基于用户发送的消息的搜索结果:</span><br><span class="line">&#123;search_results&#125;</span><br><span class="line">在我给你的搜索结果中，每个结果都是[webpage X begin]...[webpage X end]格式的，X代表每篇文章的数字索引。请在适当的情况下在句子末尾引用上下文。请按照引用编号[citation:X]的格式在答案中对应部分引用上下文。如果一句话源自多个上下文，请列出所有相关的引用编号，例如[citation:3][citation:5]，切记不要将引用集中在最后返回引用编号，而是在答案对应部分列出。</span><br><span class="line">在回答时，请注意以下几点：</span><br><span class="line">- 今天是&#123;cur_date&#125;。</span><br><span class="line">- 并非搜索结果的所有内容都与用户的问题密切相关，你需要结合问题，对搜索结果进行甄别、筛选。</span><br><span class="line">- 对于列举类的问题（如列举所有航班信息），尽量将答案控制在10个要点以内，并告诉用户可以查看搜索来源、获得完整信息。优先提供信息完整、最相关的列举项；如非必要，不要主动告诉用户搜索结果未提供的内容。</span><br><span class="line">- 对于创作类的问题（如写论文），请务必在正文的段落中引用对应的参考编号，例如[citation:3][citation:5]，不能只在文章末尾引用。你需要解读并概括用户的题目要求，选择合适的格式，充分利用搜索结果并抽取重要信息，生成符合用户要求、极具思想深度、富有创造力与专业性的答案。你的创作篇幅需要尽可能延长，对于每一个要点的论述要推测用户的意图，给出尽可能多角度的回答要点，且务必信息量大、论述详尽。</span><br><span class="line">- 如果回答很长，请尽量结构化、分段落总结。如果需要分点作答，尽量控制在5个点以内，并合并相关的内容。</span><br><span class="line">- 对于客观类的问答，如果问题的答案非常简短，可以适当补充一到两句相关信息，以丰富内容。</span><br><span class="line">- 你需要根据用户要求和回答内容选择合适、美观的回答格式，确保可读性强。</span><br><span class="line">- 你的回答应该综合多个相关网页来回答，不能重复引用一个网页。</span><br><span class="line">- 除非用户要求，否则你回答的语言需要和用户提问的语言保持一致。</span><br><span class="line"></span><br><span class="line"># 用户消息为：</span><br><span class="line">&#123;question&#125;&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure>

<p>这里最大的难点可能不是技术问题，而是去哪里找免费的搜索引擎接口？下面是我搜集的一些常用的搜索服务：- <a target="_blank" rel="noopener" href="https://open.bochaai.com/">博查搜索 API</a> - 国内不错的搜索服务，不免费，但确实便宜，一次调用 3 分钱. 除了这些通用搜索服务，还有一些领域类搜索，比如学术搜索可以用 <a target="_blank" rel="noopener" href="https://serpapi.com/google-scholar-api">Google Scholar API</a>、<a target="_blank" rel="noopener" href="https://info.arxiv.org/help/api/index.html">arXiv API</a> 等；本地商业搜索可以用 <a target="_blank" rel="noopener" href="https://docs.developer.yelp.com/docs/fusion-intro">Yelp Fusion API</a>、<a target="_blank" rel="noopener" href="https://lbs.amap.com/product/search">高德地图 API</a> 等。</p>
<h2 id="AI-深度搜索（Deep-Search）"><a href="#AI-深度搜索（Deep-Search）" class="headerlink" title="AI + 深度搜索（Deep Search）"></a>AI + 深度搜索（Deep Search）</h2><p><strong>朴素 RAG</strong> 的弊端很快便浮现了出来：<strong>RAG 中最核心的问题是 R，也就是检索</strong>，在面对模糊问题时，检索结果的精确性往往不高，面对复杂问题时，单次检索又不足以获取足够的上下文信息；为了解决这些问题，人们又提出了 <strong>高级 RAG</strong> 和 <strong>模块化 RAG</strong> 等概念，通过 <strong>查询重写（Query Rewriting）</strong>、<strong>查询扩展（Query Expansion）</strong> 等方法将用户的原始问题转换成更清晰、更适合检索的任务，这种方法也被称为 <strong>查询转换（Query Transformation）</strong>：<br>![[ObsidianPicture&#x2F;Pasted image 20251002220630.png]]</p>
<p>在过去的一年里，RAG 技术日新月异，感兴趣的可以参见我之前写的 <a target="_blank" rel="noopener" href="https://www.aneasystone.com/archives/2024/06/advanced-rag-notes.html">高级 RAG 技术学习笔记</a> 这篇笔记。</p>
<h3 id="Graph-RAG"><a href="#Graph-RAG" class="headerlink" title="Graph RAG"></a>Graph RAG</h3><p>尽管如此，传统 RAG 在面对更复杂的问题时仍然是捉襟见肘，这些问题往往需要更深入搜索和推理，具体包括：</p>
<ul>
<li><p><strong>全局性问题理解</strong>：传统 RAG 主要依赖向量检索，擅长回答局部的、具体的问题，但难以处理需要跨文档推理的全局性问题；</p>
<ul>
<li>近五年人工智能领域的论文中，哪些研究方向的热度增长最快？</li>
</ul>
</li>
<li><p><strong>复杂语义关系问答</strong>：传统 RAG 忽略了实体间的语义关系，导致回答缺乏逻辑连贯性；</p>
<ul>
<li>《哪吒2》是哪个公司发行的，这个公司还发行过哪些票房超10亿的电影？</li>
</ul>
</li>
<li><p><strong>多跳推理问题</strong>：传统 RAG 无法处理需要多步推理的问题，因为向量检索仅返回单篇文档片段；</p>
<ul>
<li>《哪吒2》中哪吒配音的老家天气怎么样？</li>
</ul>
</li>
<li><p><strong>复杂条件筛选</strong>：依赖关键词匹配可能漏检，无法处理复合逻辑条件；</p>
<ul>
<li>找出所有总部在加州、员工超过1万人，且创始人毕业于斯坦福的科技公司。</li>
</ul>
</li>
</ul>
<p>2024 年上半年，微软公开了 <strong>Graph RAG</strong> 的论文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused Summarization</a>，将知识图谱的概念引入 RAG 中，通过结构化信息提升大模型生成内容的准确性、相关性和可解释性。在年中的时候，<a target="_blank" rel="noopener" href="https://github.com/microsoft/graphrag">Graph RAG</a> 正式开源，在社区引起了相当的热度，在很短时间内就超过了上万星标。<br>![[ObsidianPicture&#x2F;Pasted image 20251002220713.png]]</p>
<h3 id="Agentic-RAG"><a href="#Agentic-RAG" class="headerlink" title="Agentic RAG"></a>Agentic RAG</h3><p>上面这些 RAG 的流程基本上都是线性的，遵循着 <strong>检索-生成-结束</strong> 这样的固定流程。后来，随着智能体的兴起，又出现了 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.09136">Agentic RAG</a> 的概念，这是传统 RAG 的进阶范式，将智能体的任务规划、工具使用、反思重试等机制引入 RAG 流程中。<br>![[ObsidianPicture&#x2F;Pasted image 20251002220750.png]]</p>
<p>智能体的核心是 <strong>思考-行动-观察</strong> 循环，这三个组件在一个持续的循环中协同工作，从而实现智能体的自主性、交互性和决策能力。将智能体引入 RAG 系统，可以让其具备更动态、更灵活的检索与生成能力；最直观的表现就是反复的检索，比如切换不同的数据源（工具使用），切换不同的检索词（子任务拆解、反思），直到用户问题解决为止。<br>![[ObsidianPicture&#x2F;Pasted image 20251002221341.png]]<br>Agentic RAG 的典型能力如下：</p>
<ul>
<li><strong>动态检索</strong>：根据生成内容的中间结果，决定是否需要二次检索，发现答案不完整时自动触发新搜索；或者根据问题类型主动选择检索源，比如优先查数据库还是通用搜索引擎；</li>
<li><strong>任务分解</strong>：将复杂问题拆解为子任务，比如用户的问题是 “对比 A 和 B”，那么需要先检索 A 的特性，再检索 B 的特性，最后综合比较；</li>
<li><strong>工具调用</strong>：让 RAG 不仅仅局限于检索，也可以调用外部工具获取实时信息，比如查询股票价格和天气情况；又或者执行计算或生成代码，比如通过 Python 代码分析数据，再生成结论；</li>
<li><strong>反思与修正</strong>：对生成结果自我评估，发现不足时重新检索或调整生成策略，比如在生成报告时发现缺少某部分数据时能自动补充；</li>
<li><strong>多轮交互</strong>：在对话中主动追问用户以澄清需求，比如用户的要求是 “帮我找一些关于人工智能的论文”，可以追问要找的是什么领域，是 NLP 还是计算机视觉。</li>
</ul>
<p>有很多关于 Agentic RAG 的开源实现，比如 <a target="_blank" rel="noopener" href="https://www.llamaindex.ai/blog/agentic-rag-with-llamaindex-2721b8a49ff6">LlamaIndex</a>、<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/">LangGraph</a>、<a target="_blank" rel="noopener" href="https://huggingface.co/learn/cookbook/agent_rag">smolagents</a> 等教程。</p>
<h3 id="Deep-Search"><a href="#Deep-Search" class="headerlink" title="Deep Search"></a>Deep Search</h3><p>接下来，我们再来看下什么是 <strong>深度搜索（Deep Search）</strong>？其实，目前学术界并没有这个概念的明确定义，只是有几个产品或开源项目是以这个命名的，比如 <a target="_blank" rel="noopener" href="https://x.ai/news/grok-3">Grok 3</a> 中推出的 DeepSearch 和 DeeperSearch 功能, 在回答问题时会经过 <strong>思考-搜索-分析-验证</strong> 等步骤. 这和上面的 Agentic RAG 使用的 <strong>思考-行动-观察</strong> 循环如出一辙，所以本质上来说，<strong>Deep Search 就是 Agentic RAG</strong>。</p>
<p>另一个是 Jina AI 推出的 <a target="_blank" rel="noopener" href="https://jina.ai/deepsearch/">深度搜索 API</a> 服务，它会对用户的问题进行广泛搜索并经过多次迭代，然后给出答案。<br>![[ObsidianPicture&#x2F;Pasted image 20251002221520.png]]<br>这个 API 和 OpenAI 的接口基本一致，所以很容易接入我们的应用中，官方也提供了 <a target="_blank" rel="noopener" href="https://search.jina.ai/">对话页面</a> 可以体验。同时，这还是一个开源项目，项目名叫 <a target="_blank" rel="noopener" href="https://github.com/jina-ai/node-DeepResearch">jina-ai&#x2F;node-DeepResearch</a>，虽然名称里有 DeepResearch 但是实际上它只有 DeepSearch 的功能，感兴趣的同学可以去扒一扒它的源码，官方还贴心地写了两篇公众号文章对其实现原理做了详细的讲解，推荐一读：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/-pPhHDi2nz8hp5R3Lm_mww">DeepSearch 与 DeepResearch 的设计和实现</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/apnorBj4TZs3-Mo23xUReQ">DeepSearch&#x2F;DeepResearch 中最优文本段选择和 URL 重排</a></li>
</ul>
<p>还有一个是 <a target="_blank" rel="noopener" href="https://zilliz.com/">Zilliz</a> 公司（就是开源 Milvus 向量数据库的那家公司）开源的项目 <a target="_blank" rel="noopener" href="https://github.com/zilliztech/deep-searcher">zilliztech&#x2F;deep-searcher</a>：<br>![[ObsidianPicture&#x2F;Pasted image 20251002221705.png]]</p>
<p>细读它的源码可以发现，它主要分为两个部分：</p>
<ol>
<li><p>离线数据处理：通过各种 <code>file_loader</code> 和 <code>web_crawler</code> 加载文件和网页，切片后生成向量，构建离线数据；其中 <code>web_crawler</code> 使用了 <a target="_blank" rel="noopener" href="https://jina.ai/reader">Jina Reader</a>、<a target="_blank" rel="noopener" href="https://www.firecrawl.dev/">Firecrawl</a>、<a target="_blank" rel="noopener" href="https://docs.crawl4ai.com/">Crawl4AI</a> 等接口实现网页内容的爬取；</p>
</li>
<li><p>在线实时问答：代码中实现了两个 Agent，根据问题的类型路由到对应的 Agent 来处理：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/zilliztech/deep-searcher/blob/master/deepsearcher/agent/chain_of_rag.py">ChainOfRAG</a>：这个 Agent 可以分解复杂的查询，并逐步找到子查询的事实信息，它非常适合处理具体的事实查询和多跳问题；</li>
<li><a target="_blank" rel="noopener" href="https://github.com/zilliztech/deep-searcher/blob/master/deepsearcher/agent/deep_search.py">DeepSearch</a>：这个 Agent 适合处理一般和简单的查询，例如给定一个主题，然后撰写报告、调查或文章。</li>
</ul>
</li>
</ol>
<p>下面是我画的一个粗略的流程图：<br><img src="https://www.aneasystone.com/usr/uploads/2025/04/3486305231.png" alt="zilliz-deep-searcher-2.png" title="zilliz-deep-searcher-2.png"><br>![[ObsidianPicture&#x2F;Pasted image 20251002221743.png]]<br>其中 <code>ChainOfRAG</code> 借鉴了 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.14342">Chain-of-Retrieval Augmented Generation</a> 这篇论文中的思路。可以看到两种 Agent 都具备 Agentic RAG 循环的特点，循环里的每一步都是通过调用大模型来实现的，使用了不少的 Prompt 技巧。</p>
<p>和 Jina AI 的 <code>node-DeepResearch</code> 项目对比一下可以发现，Zilliz 的 <code>deep-searcher</code> 依赖于向量数据库，着重聚焦于对私有数据的深度检索。虽然两者都有使用 <a target="_blank" rel="noopener" href="https://jina.ai/reader">Jina Reader</a> 接口，但是 <code>node-DeepResearch</code> 是作为搜索接口，用户对话时实时请求，而 <code>deep-searcher</code> 是用来构建离线数据。另外，Zilliz 也发布了几篇公众号文章，不过其标题和内容颇具争议，在网上引发了不少的讨论，也可以参考下。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/gLyaLhWWDj1WoDSxEwpT6Q">别搞 Graph RAG 了，拥抱新一代 RAG 范式 DeepSearcher</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/N-oPDmkb3EKqB2IM_reO1A">DeepSearcher 深度解读：Agentic RAG 的出现，传统 RAG 的黄昏</a></li>
</ul>
<h2 id="AI-深度研究（Deep-Research）"><a href="#AI-深度研究（Deep-Research）" class="headerlink" title="AI + 深度研究（Deep Research）"></a>AI + 深度研究（Deep Research）</h2><p>其实，深度搜索早已不是什么新鲜概念，早在两年前就有不少产品提供类似的功能，比如 <a target="_blank" rel="noopener" href="https://www.tiangong.cn/">天工 AI 搜索</a>，号称 “国内第一款AI搜索产品”，于 2023 年 8 月就已经上线了：</p>
<p>他们都是在大模型兴起之初就开始 AI + 深度搜索 这方面的研究了，那为什么到今天，这个概念才开始引起各方的关注呢？</p>
<h3 id="Deep-Research-演进历史"><a href="#Deep-Research-演进历史" class="headerlink" title="Deep Research 演进历史"></a>Deep Research 演进历史</h3><p>我们不妨梳理和回顾下 AI 圈近几个月发生的一些重要事件：</p>
<ul>
<li>2024 年 9 月，OpenAI 发布 <a target="_blank" rel="noopener" href="https://openai.com/index/introducing-openai-o1-preview/">o1-preview</a>，该模型在回答之前会花更多时间思考，使其在复杂推理任务、科学和编程方面显著优于其他模型；</li>
<li>2024 年 10 月，Anthropic 推出 <a target="_blank" rel="noopener" href="https://www.anthropic.com/news/3-5-models-and-computer-use">Computer Use</a> 功能，使 AI 能像人类一样操作电脑，通过观看屏幕截图，实现移动光标、点击按钮、使用虚拟键盘输入文本等操作，真正模拟人类与计算机的交互；</li>
<li>2024 年 12 月 11 号，Google 发布 Gemini 2.0 Flash，同时还给 Gemini 带了一项名为 <a target="_blank" rel="noopener" href="https://blog.google/products/gemini/google-gemini-deep-research/">Deep Research</a> 的新能力，利用高级推理和长文本处理能力，Deep Research 可以充当个人的研究助理，比如用来做一些复杂的研究报告；</li>
<li>2024 年 12 月 19 号，Google 紧接着又发布了 <a target="_blank" rel="noopener" href="https://deepmind.google/technologies/gemini/flash-thinking/">Gemini 2.0 Flash Thinking</a> 公开预览版，这也是一种思考模型，可以在模型生成回答时查看其思考过程，并生成具有更强推理能力的回答；</li>
<li>2025 年 1 月 20 号，深度求索的 <a target="_blank" rel="noopener" href="https://api-docs.deepseek.com/news/news250120">DeepSeek-R1</a> 横空出世，用极低的成本达到了比肩 OpenAI o1 的水平，在全球市场上掀起了一股前所未有的热潮，也潜移默化地把 “推理模型” 这个概念带给了千家万户，将思考过程渲染在聊天界面已经变成了一种标准做法；</li>
<li>2025 年 1 月 23 号，OpenAI 发布 <a target="_blank" rel="noopener" href="https://openai.com/index/introducing-operator/">Operator</a> 智能体，和 Anthropic 的 Computer Use 类似，可以操作浏览器，为用户执行各种复杂任务；</li>
<li>2025 年 2 月 2 号，OpenAI 又发布了 <a target="_blank" rel="noopener" href="https://openai.com/index/introducing-deep-research/">Deep Research</a> 功能，它可以自动搜集大量的网络信息，利用推理能力综合分析，为用户完成更为复杂的研究任务，能在几十分钟内完成人类需要数小时才能完成的工作；</li>
<li>2025 年 2 月 14 号，Perplexity 紧随其后，同样也发布了 <a target="_blank" rel="noopener" href="https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research">Deep Research</a> 功能，能够执行多次搜索、阅读大量来源并生成全面报告；</li>
<li>2025 年 2 月 19 号，xAI 推出 <a target="_blank" rel="noopener" href="https://x.ai/news/grok-3">Grok-3</a>，内置 DeepSearch 和 DeeperSearch 功能；</li>
<li>2025 年 2 月 25 号，阿里 Qwen 团队发布推理模型 <a target="_blank" rel="noopener" href="https://qwenlm.github.io/zh/blog/qwq-max-preview/">QwQ-Max-Preview</a>，它基于 <code>Qwen2.5-Max</code> 构建，在数学、编程以及通用任务中展现了更强的能力，同时在 Agent 相关的工作流中也有不错的表现；</li>
<li>2025 年 3 月 5 号，Google 面向 Google One AI Premium 订阅用户推出 <a target="_blank" rel="noopener" href="https://blog.google/products/search/ai-mode-search/">AI Mode</a> 功能，提供对话式搜索体验，支持复杂多轮提问；</li>
<li>2025 年 3 月 6 号，中国 AI 创业公司 Monica 发布 <a target="_blank" rel="noopener" href="https://manus.im/">Manus</a>，号称 “全球首款通用 AI 代理”，其应用场景覆盖旅行规划、股票分析、教育内容生成等 40 余个领域；据称，Manus 在 GAIA 基准测试中刷新了 SOTA 记录，性能远超同类产品，凭借 KOL 助力，一时间刷屏全网，内测邀请码一码难求，甚至被炒到 5 万块钱；</li>
<li>2025 年 3 月 31 号，在中关村论坛智谱 Open Day 上，智谱发布了 <a target="_blank" rel="noopener" href="https://autoglm-research.zhipuai.cn/">AutoGLM 沉思</a>，这又是一款 Deep Research 类智能体，它能够模拟人类的思维过程，完成从数据检索、分析到生成报告的全过程；</li>
</ul>
<p>可以看出 2025 年刚过去四分之一，Deep Research 就已经开始卷起来了。这其中，OpenAI 发布的 <code>o1-preview</code> 和深度求索发布的 <code>DeepSeek-R1</code> 是两个关键里程碑，Gemini 2.0 Flash Thinking 和 QwQ 穷追不舍，这些都被称为推理模型（或思考模型），他们引入了 <strong>推理时计算（test-time compute）</strong> 的概念，也就是在推理阶段投入更多的计算资源，例如评估多个潜在答案、进行更深入的规划、以及在给出最终答案前进行自我反思等。</p>
<p>心理学家卡尼曼提出，人类大脑中存在两套系统：系统1和系统2，系统1是无意识的、快速的、直观的，而系统2则是有意识的、缓慢的、需要付出心理努力的，这两套系统在我们日常生活中相互作用，共同影响着我们的思考、决策和行为。</p>
<p>传统模型和推理模型就好比是人类大脑中的系统1和系统2，推理模型用更长的等待时间，换取更高质量、更具实用性的结果。就像著名的 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%A3%89%E8%8A%B1%E7%B3%96%E5%AE%9E%E9%AA%8C">斯坦福棉花糖实验</a>，那些为了获得两个棉花糖而坚持忍耐更长时间的孩子，往往能取得更好的长期成就。推理模型的发展其实是在引导用户接受一种 <strong>延迟满足</strong> 的观念，为了获得更好的结果，用户需要等待更长的处理时间，无论你是否喜欢这种用户体验，大多数用户都已经默默接受了这一点。</p>
<p>正是在这个背景下，Deep Research 开始流行起来，因为 Deep Research 天生需要深度思考和推理。</p>
<h3 id="Deep-Research-示例"><a href="#Deep-Research-示例" class="headerlink" title="Deep Research 示例"></a>Deep Research 示例</h3><p>Deep Research 和 Deep Search 的概念由于并没有明确定义，往往被混淆，但在我看来，Deep Research 相比于 Deep Search 有几个更明显的特征：</p>
<ul>
<li>引入推理模型，思考时间更长，能处理更复杂的任务；</li>
<li>能使用更多的工具，比如操作电脑、访问浏览器、编写代码等；</li>
<li>更擅长论文写作和报告生成；</li>
</ul>
<p>Gemini 的 Deep Research 功能可以结合思考模型和联网搜索对话题进行深度剖析：<br>最近秘塔推出了一个 <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/sk0KF9c1MPhpS2oGH-UIKA">生成互动网页</a> 的功能，可以将搜索的内容整合成一份图文并茂的研究报告：</p>
<h3 id="Deep-Research-开源实现"><a href="#Deep-Research-开源实现" class="headerlink" title="Deep Research 开源实现"></a>Deep Research 开源实现</h3><p>目前 Deep Research 开源实现非常多，这一节将挑选几个比较流行的逐一介绍下。</p>
<h4 id="assafelovic-gpt-researcher"><a href="#assafelovic-gpt-researcher" class="headerlink" title="assafelovic&#x2F;gpt-researcher"></a>assafelovic&#x2F;gpt-researcher</h4><p><a target="_blank" rel="noopener" href="https://github.com/assafelovic/gpt-researcher">GPT Researcher</a> 也被简称为 GPTR，应该是大模型兴起之后最早一批专注于研究报告生成的开源项目。受 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.04091">Plan-and-Solve</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.11401">RAG</a> 和 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.14207">STORM</a> 等论文的启发，GPT Researcher 将系统划分成 <strong>规划者（Planner）</strong>、<strong>研究者（Researcher）</strong> 和 <strong>发布者（Publisher）</strong> 三个部分：</p>
<p>其中规划者生成研究问题，而研究者根据每个生成的研究问题寻找最相关的信息，最后，发布者筛选和汇总所有相关信息，并生成一份研究报告。</p>
<p>要体验 GPT Researcher，首先下载源码：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>$ git clone [https://github.com/assafelovic/gpt-researcher.git](https://github.com/assafelovic/gpt-researcher.git)</code></td>
</tr>
</tbody></table>
<p>然后进入项目根目录：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>$ cd gpt-researcher</code></td>
</tr>
</tbody></table>
<p>目录下有一个 <code>.env.example</code> 文件，复制这个文件并重命名为 <code>.env</code>，然后填写 <code>OPENAI_API_KEY</code> 和 <code>TAVILY_API_KEY</code> 两个环境变量：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2<br><br>3<br><br>4</td>
<td><code>$ cp .env.example .env</code><br><br><code>$ vi .env</code><br><br><code>OPENAI_API_KEY=xxx</code><br><br><code>TAVILY_API_KEY=xxx</code></td>
</tr>
</tbody></table>
<p>接下来安装所需依赖：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>$ pip install -r requirements.txt</code></td>
</tr>
</tbody></table>
<p>安装完成后运行：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>$ python -m uvicorn main:app --reload</code></td>
</tr>
</tbody></table>
<p>这时就可以通过 <code>http://localhost:8000</code> 访问并使用 GPT Researcher 了。</p>
<p>要注意的是，这个页面是用 <a target="_blank" rel="noopener" href="https://docs.gptr.dev/docs/gpt-researcher/frontend/vanilla-js-frontend">纯 JS</a> 实现的，不依赖其他 JS 库，所以体验不怎么好，而且更新有些滞后，有些最新特性体验不了。官方还提供了另一个 <a target="_blank" rel="noopener" href="https://docs.gptr.dev/docs/gpt-researcher/frontend/nextjs-frontend">Next.js 版本</a> 的实现，可以通过下面的步骤启动：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2<br><br>3</td>
<td><code>$ cd frontend/nextjs</code><br><br><code>$ npm install --legacy-peer-deps</code><br><br><code>$ npm run dev</code></td>
</tr>
</tbody></table>
<p>启动成功后，可以通过 <code>http://localhost:3000</code> 访问新 UI：</p>
<p>最后，最上面的 <code>Report Type</code> 选项，也是最重要的选项，这个表示生成报告的策略，GPT Researcher 支持四种不同的策略：</p>
<ul>
<li><strong>Summary</strong> - 篇幅短，速度快，生成时间 2min 左右</li>
<li><strong>Detailed</strong> - 篇幅长，内容更有深度，生成时间 5min 左右</li>
<li><strong>Deep Research Report</strong> - 使用 <a target="_blank" rel="noopener" href="https://docs.gptr.dev/blog/2025/02/26/deep-research">深度研究方式</a> 生成报告</li>
<li><strong>Multi Agents Report</strong> - 使用 <a target="_blank" rel="noopener" href="https://docs.gptr.dev/blog/gptr-langgraph">多智能体方式</a> 生成报告</li>
</ul>
<p>对这几种不同的生成策略进行了简单的梳理，画了个流程图<br><img src="https://www.aneasystone.com/usr/uploads/2025/04/361427675.png" alt="gpt-researcher-flow.png" title="gpt-researcher-flow.png"></p>
<h4 id="dzhng-deep-research"><a href="#dzhng-deep-research" class="headerlink" title="dzhng&#x2F;deep-research"></a>dzhng&#x2F;deep-research</h4><p><a target="_blank" rel="noopener" href="https://github.com/dzhng/deep-research">dzhng&#x2F;deep-research</a> 这个项目是由 <a target="_blank" rel="noopener" href="https://www.aomni.com/">Aomni</a> 的 CEO <a target="_blank" rel="noopener" href="https://github.com/dzhng">David Zhang</a> 开发，在 Github 开源后非常受欢迎，很快便成为万星项目。该项目架构简单易懂，核心代码不过 300 行，允许用户调整研究广度和深度，默认通过 <a target="_blank" rel="noopener" href="https://www.firecrawl.dev/">Firecrawl</a> 作为信息搜索和抓取的工具，针对用户提供的主题不断探索发现，直到完成用户的研究目标。</p>
<p>下面简单体验下该项目，首先下载源码并进入工作目录：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2</td>
<td><code>$ git clone [https://github.com/dzhng/deep-research.git](https://github.com/dzhng/deep-research.git)</code><br><br><code>$ cd deep-research</code></td>
</tr>
</tbody></table>
<p>修改环境变量：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2<br><br>3<br><br>4</td>
<td><code>$ cp .env.example .env.local</code><br><br><code>$ vi .env.local</code><br><br><code>FIRECRAWL_KEY=xxx</code><br><br><code>OPENAI_KEY=xxx</code></td>
</tr>
</tbody></table>
<p>安装所需依赖：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>$ npm install</code></td>
</tr>
</tbody></table>
<p>然后运行：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>$ npm start</code></td>
</tr>
</tbody></table>
<p>这是一个命令行程序，运行后首先会询问你想研究什么主题，并让你填写研究的广度和深度，以及最后希望生成报告还是答案：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2<br><br>3<br><br>4</td>
<td><code>What would you like to research? A2A</code><br><br><code>Enter research breadth (recommended 2-10, default 4): 3</code><br><br><code>Enter research depth (recommended 1-5, default 2): 2</code><br><br><code>Do you want to generate a long report or a specific answer? (report/answer, default report): report</code></td>
</tr>
</tbody></table>
<p>最近 Google 的 A2A 协议比较火，我就让它帮我生成一份 A2A 的调研报告，其中研究广度指的是根据你输入的主题生成 N 个子 query 进行并发搜索和研究，研究深度指的是根据搜索出来的结果进一步生成研究主题的次数，填写完这些信息后，程序会向用户提三个问题，进一步澄清要研究的主题：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">`Creating research plan...`</span><br><span class="line"></span><br><span class="line">`To better understand your research needs, please answer these follow-up questions:`</span><br><span class="line"></span><br><span class="line">`Can you please clarify the meaning of &#x27;A2A&#x27; in your query? For instance, are you referring to an &#x27;ask-to-answer&#x27; platform mechanism, &#x27;asset-to-asset&#x27; exchange, or another concept entirely?`</span><br><span class="line"></span><br><span class="line">`Your answer: google a2a protocol`</span><br><span class="line"></span><br><span class="line">`Could you specify the context or domain where &#x27;A2A&#x27; is being applied (e.g., finance, technology, social media)?`</span><br><span class="line"></span><br><span class="line">`Your answer: technology`</span><br><span class="line"></span><br><span class="line">`What specific aspects of &#x27;A2A&#x27; are you interested in exploring (e.g., technical functionality, market impact, user engagement, etc.)?`</span><br><span class="line"></span><br><span class="line">`Your answer: technical functionality`</span><br></pre></td></tr></table></figure>

<p>这里可以看到，由于 A2A 是新发布的协议，大模型并不知道是什么，所以需要我们明确输入。回答完三个问题后，就开始深度研究了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">`Starting research...`</span><br><span class="line"></span><br><span class="line">`Created 3 queries [`</span><br><span class="line"></span><br><span class="line">  `&#123;`</span><br><span class="line"></span><br><span class="line">    `query: &#x27;Google A2A protocol technical functionality overview&#x27;,`</span><br><span class="line"></span><br><span class="line">    `researchGoal: &#x27;This query aims to gather comprehensive documentation and analysis of ...&#x27;`</span><br><span class="line"></span><br><span class="line">  `&#125;,`</span><br><span class="line"></span><br><span class="line">  `&#123;`</span><br><span class="line"></span><br><span class="line">    `query: &#x27;Google A2A protocol design principles and implementation details&#x27;,`</span><br><span class="line"></span><br><span class="line">    `researchGoal: &#x27;The goal here is to uncover in-depth information about the design philosophies and ...&#x27;`</span><br><span class="line"></span><br><span class="line">  `&#125;,`</span><br><span class="line"></span><br><span class="line">  `&#123;`</span><br><span class="line"></span><br><span class="line">    `query: &#x27;Performance and scalability evaluation of the Google A2A protocol&#x27;,`</span><br><span class="line"></span><br><span class="line">    `researchGoal: &#x27;This query targets technical performance metrics and scalability aspects of the Google A2A protocol ...&#x27;`</span><br><span class="line"></span><br><span class="line">  `&#125;`</span><br><span class="line"></span><br><span class="line">`]`</span><br><span class="line"></span><br><span class="line">`Ran Google A2A protocol technical functionality overview, found 4 contents`</span><br><span class="line"></span><br><span class="line">`Ran Google A2A protocol design principles and implementation details, found 4 contents`</span><br></pre></td></tr></table></figure>

<p>经过大约 3 分钟时间，一份 7 页的研究报告就生成好了</p>
<p>下面是大致的程序流程图</p>
<p>![[ObsidianPicture&#x2F;Pasted image 20251002222411.png]]</p>
<p>此外，有热心网友为这个程序做了 <a target="_blank" rel="noopener" href="https://github.com/AnotiaWang/deep-research-web-ui">Web 页面</a>，你也可以 <a target="_blank" rel="noopener" href="https://deep-research.ataw.top/">在线体验</a>：</p>
<h4 id="sentient-agi-OpenDeepSearch"><a href="#sentient-agi-OpenDeepSearch" class="headerlink" title="sentient-agi&#x2F;OpenDeepSearch"></a>sentient-agi&#x2F;OpenDeepSearch</h4><p><a target="_blank" rel="noopener" href="https://github.com/sentient-agi/OpenDeepSearch">sentient-agi&#x2F;OpenDeepSearch</a> 是另一个比较热门的 Deep Research 开源项目，我们来体验下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2</td>
<td><code>$ git clone [https://github.com/sentient-agi/OpenDeepSearch.git](https://github.com/sentient-agi/OpenDeepSearch.git)</code><br><br><code>$ cd OpenDeepSearch</code></td>
</tr>
</tbody></table>
<p>安装 OpenDeepSearch：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2</td>
<td><code>$ pip install -e .</code><br><br><code>$ pip install -r requirements.txt</code></td>
</tr>
</tbody></table>
<p>修改环境变量：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2<br><br>3<br><br>4<br><br>5<br><br>6<br><br>7</td>
<td><code>SERPER_API_KEY=xxx</code><br><br><code>JINA_API_KEY=xxx</code><br><br><code>OPENAI_API_KEY=xxx</code><br><br><code>OPENAI_API_BASE=xxx</code><br><br><code>LITELLM_MODEL_ID=gpt-4o-mini</code></td>
</tr>
</tbody></table>
<p>主要包括三个部分：</p>
<ol>
<li>搜索引擎配置：项目默认使用 <a target="_blank" rel="noopener" href="https://serper.dev/">Serper</a> 作为搜索引擎，也支持使用 <a target="_blank" rel="noopener" href="https://github.com/searxng/searxng">SearXNG</a> 搭建自己的聚合搜索引擎；</li>
<li>重排序配置：项目默认使用 <a target="_blank" rel="noopener" href="https://jina.ai/">Jina</a> 作为重排序工具，也支持使用 <a target="_blank" rel="noopener" href="https://github.com/michaelfeil/infinity">Infinity</a> 搭建自己的 Embeddings 服务；</li>
<li>大模型配置：项目使用 <a target="_blank" rel="noopener" href="https://github.com/BerriAI/litellm">LiteLLM</a> 对接大模型，支持多达 100+ 不同的大模型；</li>
</ol>
<p>OpenDeepSearch 可以作为工具库直接调用：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2<br><br>3<br><br>4<br><br>5<br><br>6<br><br>7<br><br>8<br><br>9<br><br>10<br><br>11<br><br>12<br><br>13</td>
<td><code>from opendeepsearch import OpenDeepSearchTool</code><br><br><code>search_agent = OpenDeepSearchTool(</code><br><br>    <code>model_name=&quot;gpt-4o-mini&quot;,</code><br><br>    <code>reranker=&quot;jina&quot;</code><br><br><code>)</code><br><br><code>if not search_agent.is_initialized:</code><br><br>    <code>search_agent.setup()</code><br><br><code>query = &quot;Fastest land animal?&quot;</code><br><br><code>result = search_agent.forward(query)</code><br><br><code>print(result)</code></td>
</tr>
</tbody></table>
<p>由于 <code>OpenDeepSearchTool</code> 实现了 <a target="_blank" rel="noopener" href="https://github.com/huggingface/smolagents">smolagents</a> 的 <code>Tool</code> 接口，所以也可以集成到 smolagents 智能体框架中作为工具调用，比如下面使用 <code>ToolCallingAgent</code> 创建一个 ReAct 智能体：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1<br><br>2<br><br>3<br><br>4<br><br>5<br><br>6<br><br>7<br><br>8<br><br>9<br><br>10<br><br>11<br><br>12<br><br>13<br><br>14<br><br>15<br><br>16<br><br>17<br><br>18<br><br>19<br><br>20<br><br>21<br><br>22<br><br>23</td>
<td><code>from opendeepsearch import OpenDeepSearchTool</code><br><br><code>from opendeepsearch.wolfram_tool import WolframAlphaTool</code><br><br><code>from opendeepsearch.prompts import REACT_PROMPT</code><br><br><code>from smolagents import LiteLLMModel, ToolCallingAgent</code><br><br><code>model = LiteLLMModel(</code><br><br>    <code>&quot;gpt-4o-mini&quot;,</code><br><br>    <code>temperature=0.7</code><br><br><code>)</code><br><br><code>search_agent = OpenDeepSearchTool(</code><br><br>    <code>model_name=&quot;gpt-4o-mini&quot;,</code><br><br>    <code>reranker=&quot;jina&quot;</code><br><br><code>)</code><br><br><code>wolfram_tool = WolframAlphaTool(app_id=os.environ[&quot;WOLFRAM_ALPHA_APP_ID&quot;])</code><br><br><code>react_agent = ToolCallingAgent(</code><br><br>    <code>tools=[search_agent, wolfram_tool],</code><br><br>    <code>model=model,</code><br><br>    <code>prompt_templates=REACT_PROMPT</code><br><br><code>)</code><br><br><code>query = &quot;How long would a cheetah at full speed take to run the length of Pont Alexandre III?&quot;</code><br><br><code>result = react_agent.run(query)</code><br><br><code>print(result)</code></td>
</tr>
</tbody></table>
<p>这里的问题是 <code>一只猎豹以全速奔跑需要多长时间才能跑完亚历山大三世桥的长度？</code>，运行结果如下：</p>
<p>可以看到程序首先调用搜索工具得知 <code>亚历山大三世桥的长度为 160 米</code>，然后模型自己知道 <code>猎豹的奔跑速度是 30 米/秒</code>，再调用 WolframAlpha 工具计算 <code>160 / 30 = 5.333</code> 从而输出结果。</p>
<p>我们也可以使用 <code>CodeAgent</code> 创建一个 <a target="_blank" rel="noopener" href="https://github.com/huggingface/smolagents?tab=readme-ov-file#how-do-code-agents-work">Code 智能体</a>，参考 <code>gradio_demo.py</code> 示例代码：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td><code>$ python gradio_demo.py</code></td>
</tr>
</tbody></table>
<p>示例代码集成了 <a target="_blank" rel="noopener" href="https://github.com/gradio-app/gradio">Gradio</a> 框架，提供了可视化页面和智能体进行交互：</p>
<p>虽然这个项目的名字叫做 Deep Search，但是我觉得也可以将它划到 Deep Research 的范畴，主要在于它处理搜索结果的过程很值得学习，下面是调用 <code>OpenDeepSearchTool</code> 的流程图：</p>
<p>![[ObsidianPicture&#x2F;Pasted image 20251002222545.png]]</p>
<p>这里有几个点比较值得关注：</p>
<ol>
<li>提供了默认和专业两种搜索模式，专业模式会对搜索结果进一步处理；</li>
<li>处理的第一步是抓取页面内容，如果页面是 <code>wikipedia.org/wiki</code> 直接使用 <a target="_blank" rel="noopener" href="https://github.com/martin-majlis/Wikipedia-API">Wikipedia-API</a> 获取，否则使用 <a target="_blank" rel="noopener" href="https://github.com/unclecode/crawl4ai">Crawl4AI</a> 爬取；</li>
<li>将爬取的内容分成段落，使用 <a target="_blank" rel="noopener" href="https://huggingface.co/kenhktsui/llm-data-textbook-quality-fasttext-classifier-v2">kenhktsui&#x2F;llm-data-textbook-quality-fasttext-classifer-v2</a> 分类器对每个段落按 <strong>教育价值（educational value）</strong> 进行分类，过滤掉教育价值偏低的段落；</li>
<li>如果页面内容过长，则使用 LangChain 的 <code>RecursiveCharacterTextSplitter</code> 对其进行分片，再通过 <strong>重排序（Reranker）</strong> 模型筛选出和原始问题最接近的片段。</li>
</ol>
<p>可以看出 OpenDeepSearch 更擅长问答场景而不是报告生成，经过对搜索结果一系列的处理，OpenDeepSearch 在 <a target="_blank" rel="noopener" href="https://openai.com/index/introducing-simpleqa/">SimpleQA</a> 单跳查询方面的表现与闭源搜索产品相当，在 <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/google/frames-benchmark">FRAMES</a> 多跳查询上表现远超闭源搜索产品</p>
<p>![[ObsidianPicture&#x2F;Pasted image 20251002222651.png]]</p>
<p>感兴趣的可以看下他们的 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.20201">论文</a>。</p>
<h4 id="更多"><a href="#更多" class="headerlink" title="更多"></a>更多</h4><p>关于 Deep Search 和 Deep Research，还有很多优秀的开源项目，这些项目将传统的搜索技术充分融合，不仅在报告生成上有着出色的表现，而且在复杂问题的求解上也处于 SOTA 水平。比如在 OpenAI 发布 Deep Research 之后的 24 小时内，Hugging Face 就基于自家的 <a target="_blank" rel="noopener" href="https://github.com/huggingface/smolagents/tree/main/examples/open_deep_research">smolagents</a> 智能体框架实现了 <a target="_blank" rel="noopener" href="https://huggingface.co/blog/open-deep-research">Open Deep Research</a> 开源项目，能够自主浏览网页，滚动页面，处理文件，甚至编写代码对数据进行计算；在 Monica 发布 Manus 之后，MetaGPT 团队仅花费 3 小时就开发了 <a target="_blank" rel="noopener" href="https://github.com/mannaandpoem/OpenManus">OpenManus</a> 项目，也能够自主浏览网页，查询和总结信息，实现了和 Manus 类似的功能，得到社区的广泛关注；还有 LangChain 团队基于 LangGraph 多智能体框架开发的 <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/local-deep-researcher">Local Deep Researcher</a> 和 <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/open_deep_research">Open Deep Research</a> 项目，使用了和 GPT Researcher 一样的 <code>Plan and Execute</code> 思路，先用推理模型撰写报告大纲，然后针对每一节并行地搜集信息，最后生成一份详尽的调研报告，得益于 LangSmith 平台，运行过程中还能清晰地看到智能体的规划和执行链路。</p>
<p>除此之外，还有很多项目，篇幅有限，不能一一介绍。不过这些项目的实现思路大体是类似的，相信对上面几个项目的深度体验，结合对 Deep Search 和 Deep Research 原理的理解，在学习其他项目时也能一通百通。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文探讨了自 ChatGPT 引发生成式 AI 浪潮以来，信息检索与生成领域经历的快速演变，重点梳理了 <strong>AI + 搜索</strong>、<strong>深度搜索（Deep Search）</strong> 和 <strong>深度研究（Deep Research）</strong> 这三个相互关联又各有侧重的范式。</p>
<p><strong>AI + 搜索</strong> 的兴起，标志着对传统搜索引擎局限性的初步回应。通过结合大语言模型与搜索引擎，它旨在克服传统搜索体验差、信息过载的问题，并缓解大模型固有的幻觉与知识静态性。这种模式直接提供答案，简化了用户获取信息的过程，成为了各大模型产品的标配功能。然而，面对模糊或复杂问题时，其依赖单次、直接检索的 <strong>朴素 RAG</strong> 模式暴露出检索精度不足的弊端。</p>
<p><strong>深度搜索（Deep Search）</strong> 应运而生，作为对朴素 RAG 局限性的深化解决方案。它本质上是 <strong>Agentic RAG</strong> 的应用，引入了更复杂的检索策略，如查询重写、查询扩展、多步检索、以及通过智能体的 <strong>思考-行动-观察</strong> 循环进行动态、迭代式的信息搜集与初步分析。深度搜索的核心在于优化检索环节，通过更智能、更具韧性的检索过程，提升对复杂、多跳或需要全局理解问题的上下文获取能力，旨在为用户提供更精确、更相关的答案。</p>
<p><strong>深度研究（Deep Research）</strong> 则代表了当前演进的前沿。它建立在深度搜索的基础之上，但目标更为宏大，不仅追求信息的精确获取，更强调 <strong>深度分析、复杂推理、综合洞察和工具使用</strong>。其显著特征包括：</p>
<ol>
<li><strong>引入推理（思考）模型</strong>：利用如 OpenAI o1、DeepSeek-R1、Gemini 2.0 Flash Thinking 等模型，通过增加“推理时计算”换取更高质量、更具洞察力的分析结果，用户愿意接受更长的等待时间以获得“延迟满足”带来的优质内容；</li>
<li><strong>更强大的智能体能力</strong>：集成了更广泛的工具使用（如操作浏览器、执行代码、与操作系统交互）和更复杂的任务规划与分解能力；</li>
<li><strong>聚焦复杂任务与报告生成</strong>：更擅长处理需要跨领域知识整合、深度行业分析、复杂问题求解、长篇报告撰写等研究型任务，扮演着“研究助理”的角色。</li>
</ol>
<p>从 AI + 搜索到深度搜索，再到深度研究，我们见证了 AI 从简单的信息搬运工，逐步进化为能够进行初步分析的助手，最终迈向能够独立执行复杂研究任务的智能伙伴。这一演进的核心驱动力在于不断克服前一阶段的技术瓶颈，并通过引入更先进的 RAG 技术、智能体框架以及推理模型，持续提升 AI 理解、规划、执行和生成复杂内容的能力。未来，随着技术的不断融合与创新，我们有望看到更加智能、自主的研究型 AI 应用涌现。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.53ai.com/news/LargeLanguageModel/2025032069843.html">PLZ，别再误解大模型联网搜索了</a></li>
<li><a target="_blank" rel="noopener" href="https://openai.com/index/introducing-chatgpt-search/">Introducing ChatGPT search</a></li>
<li><a target="_blank" rel="noopener" href="https://www.anthropic.com/news/web-search">Claude can now search the web</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.google/products/search/ai-overviews-search-october-2024/">AI Overviews in Search are coming to more places around the world</a></li>
<li><a target="_blank" rel="noopener" href="https://x.ai/news/grok-3">Grok 3 Beta — The Age of Reasoning Agents</a></li>
<li><a target="_blank" rel="noopener" href="https://www.anthropic.com/news/3-5-models-and-computer-use">Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.google/products/gemini/google-gemini-deep-research/">Try Deep Research and our new experimental model in Gemini, your AI assistant</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/blog/open-deep-research">Open-source DeepResearch – Freeing our search agents</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/4Ai2QPYxvD5AVUUz01N0aw">「三小时复刻 Manus，GitHub 2 万星」：OpenManus 多智能体框架的技术拆解</a></li>
</ul>
<h3 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h3><ul>
<li><a target="_blank" rel="noopener" href="https://you.com/">YOU.COM</a></li>
<li><a target="_blank" rel="noopener" href="https://iask.ai/">iAsk</a></li>
<li><a target="_blank" rel="noopener" href="https://search.lepton.run/">Lepton Search</a></li>
<li><a target="_blank" rel="noopener" href="https://onionai.so/">Onion AI Search</a></li>
<li><a target="_blank" rel="noopener" href="https://scira.ai/">Scira AI</a></li>
<li><a target="_blank" rel="noopener" href="https://mindsearch.netlify.app/">思·索 MindSearch</a></li>
<li><a target="_blank" rel="noopener" href="https://www.farfalle.dev/">Farfalle</a></li>
<li><a target="_blank" rel="noopener" href="https://kagi.com/fastgpt">Kagi FastGPT</a></li>
</ul>
<hr>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/zaidmukaddam/scira">Github - zaidmukaddam&#x2F;scira</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/rashadphz/farfalle">Github - rashadphz&#x2F;farfalle</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/nilsherzig/LLocalSearch">Github - nilsherzig&#x2F;LLocalSearch</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/nashsu/FreeAskInternet">Github - nashsu&#x2F;FreeAskInternet</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/InternLM/MindSearch">Github - InternLM&#x2F;MindSearch</a></li>
</ul>
<h3 id="Deep-Search-1"><a href="#Deep-Search-1" class="headerlink" title="Deep Search"></a>Deep Search</h3><ul>
<li><a target="_blank" rel="noopener" href="https://jina.ai/deepsearch/">Jina 深度搜索</a></li>
<li><a target="_blank" rel="noopener" href="https://www.tiangong.cn/">天工 AI 搜索</a></li>
<li><a target="_blank" rel="noopener" href="https://metaso.cn/">秘塔</a></li>
<li><a target="_blank" rel="noopener" href="https://www.perplexity.ai/">Perplexity</a></li>
</ul>
<hr>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/jina-ai/node-DeepResearch">Github - jina-ai&#x2F;node-DeepResearch</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/zilliztech/deep-searcher">Github - zilliztech&#x2F;deep-searcher</a></li>
</ul>
<h3 id="Deep-Research"><a href="#Deep-Research" class="headerlink" title="Deep Research"></a>Deep Research</h3><ul>
<li><a target="_blank" rel="noopener" href="https://openai.com/index/introducing-operator/">Introducing Operator</a></li>
<li><a target="_blank" rel="noopener" href="https://openai.com/index/introducing-deep-research/">Introducing deep research</a></li>
<li><a target="_blank" rel="noopener" href="https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research">Introducing Perplexity Deep Research</a></li>
<li><a target="_blank" rel="noopener" href="https://sider.ai/wisebase/deep-research">Sider Deep Research</a></li>
<li><a target="_blank" rel="noopener" href="https://manus.im/">Manus</a></li>
<li><a target="_blank" rel="noopener" href="https://autoglm-research.zhipuai.cn/">AutoGLM 沉思</a></li>
</ul>
<hr>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/assafelovic/gpt-researcher">GitHub - assafelovic&#x2F;gpt-researcher</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/dzhng/deep-research">Github - dzhng&#x2F;deep-research</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/sentient-agi/OpenDeepSearch">Github - sentient-agi&#x2F;OpenDeepSearch</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/nickscamara/open-deep-research">Github - nickscamara&#x2F;open-deep-research</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/open_deep_research">Github - langchain-ai&#x2F;open_deep_research</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/local-deep-researcher">Github - langchain-ai&#x2F;local-deep-researcher</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/mannaandpoem/OpenManus">Github - mannaandpoem&#x2F;OpenManus</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/stanford-oval/storm">Github - stanford-oval&#x2F;storm</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/binary-husky/gpt_academic">Github - binary-husky&#x2F;gpt_academic</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/mshumer/OpenDeepResearcher">Github - mshumer&#x2F;OpenDeepResearcher</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/camel-ai/owl">Github - camel-ai&#x2F;owl</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/browser-use/browser-use">Github - browser-use&#x2F;browser-use</a></li>
</ul>
<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p><a target="_blank" rel="noopener" href="https://www.aneasystone.com/archives/2025/04/deep-search-and-research.html">https://www.aneasystone.com/archives/2025/04/deep-search-and-research.html</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://gaoguodong03.github.io/gdBlog">GuoDong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://gaoguodong03.github.io/gdBlog/2025/10/03/%E8%81%8A%E8%81%8ADeep-Search-%E5%92%8CDeep-Research/">https://gaoguodong03.github.io/gdBlog/2025/10/03/%E8%81%8A%E8%81%8ADeep-Search-%E5%92%8CDeep-Research/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://gaoguodong03.github.io/gdBlog" target="_blank">果冻小配方</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/gdBlog/tags/LLM/">LLM</a><a class="post-meta__tags" href="/gdBlog/tags/DeepSearch/">DeepSearch</a><a class="post-meta__tags" href="/gdBlog/tags/tools/">tools</a><a class="post-meta__tags" href="/gdBlog/tags/RAG/">RAG</a></div><div class="post-share"><div class="social-share" data-image="/gdBlog/./img/logoDeepsearch.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/gdBlog/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="/gdBlog/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/gdBlog/2025/10/08/Docker/" title="Docker"><img class="cover" src="/gdBlog/./img/bearbug1.jpg" onerror="onerror=null;src='/gdBlog/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Docker</div></div><div class="info-2"><div class="info-item-1">远程镜像仓库本地镜像(镜像是只读的)本地仓库 镜像版本tag版本是完全独立的,last是最新的docker pull&#x2F;push 镜像名docker images 查看本地镜像docker search 容器真正的示例,隔离网络,文件.不同容器可能会争抢资源1容器打包成镜像,再上传到仓库docker psdocker ps -adocekr start&#x2F;stop&#x2F;rm IDdocker commit -a “作者名称” -m “log信息” ID 打包成镜像docker cp 文件目录 容器ID:目标目录   从前拷贝到后docker exec -it ID &#x2F;bin&#x2F;bash  进入容器内部 dickerfile脚本 是可以通过下载文件的一些来创建脚本 网络中的映射一般是端口映射,容器端口8001映射到宿主机的8080 Docker安装不要用homebrew 以前其他软件使用下载都很顺利，但这一次安装Docker却不太行，使用了代理，但总是出现报错 Error response from daemon: Get “https://...</div></div></div></a><a class="pagination-related" href="/gdBlog/2025/10/02/%E5%85%83%E8%8A%B3%E6%8E%A5%E5%85%A5Gemini/" title="元芳接入Gemini"><img class="cover" src="/gdBlog/./img/logoZiyouzhiyi.jpg" onerror="onerror=null;src='/gdBlog/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">元芳接入Gemini</div></div><div class="info-2"><div class="info-item-1">写在前面 我的实现方式gemini是google的 所以需要注册google对应的账号,由于需要翻墙再加上需要资金往来,所以放弃这条路了.最后选择使用国内的代理网站 简易,调用了一个 API 接口, 确实挺好用的.注册链接https://jeniya.top/register?aff=tUUD 了解Gemini历程2023 年 4 月，谷歌母公司 Alphabet 首席执行官桑达尔・皮查伊合并了两个大型人工智能团队，开启 OpenAI 计划。2023 年 12 月 6 日，谷歌正式推出 Gemini 1.0 版本，包括 Gemini Ultra、Gemini Pro 和 Gemini Nano 三个不同规格。2024 年 2 月 15 日，谷歌发布 Gemini 1.5，后续又不断对其进行升级和优化，如 2024 年 5 月 15 日更新升级 Gemini 1.5 Pro 版本，同时推出 Gemini 1.5 Flash 轻量化小模型。2025 年 3 月 26 日，谷歌正式推出新一代人工智能推理模型 Gemini 2.5。 模型规格及特点Gemini Ultra：是 Gemin...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/gdBlog/2025/10/01/RAG%EF%BC%88Retrieval-AugmentedGeneration%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%EF%BC%89/" title="RAG（Retrieval-AugmentedGeneration检索增强生成）"><img class="cover" src="/gdBlog/./img/logoZiyouzhiyi.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-01</div><div class="info-item-2">RAG（Retrieval-AugmentedGeneration检索增强生成）</div></div><div class="info-2"><div class="info-item-1">写在前面RAG 是一种新兴的 AI 技术，它结合了信息检索和生成式 AI 的优势，能够在处理复杂任务时提供更准确和相关的答案。RAG 的实现过程相对简单，但是它的核心在于如何检索到相关的信息，以及如何将这些信息与 LLM 结合，这就是 RAG 的关键所在。 LLM的局限性RAG（Retrieval-Augmented Generation 检索增强生成）正如其字面意思，是通过检索信息来增强 LLM生成的能力。RAG 是一种新兴的 AI 技术，它结合了信息检索和生成式 AI 的优势，能够在处理复杂任务时提供更准确和相关的答案。 RAG 的工作原理是：首先通过检索引擎从一个大型知识库中获取相关信息，然后将这些信息通过 Prompt 工程与 LLM 结合，生成最终的答案。 为什么需要这样做呢？ LLM的特点：  会回答你很多不存在的东西，编造一些不存在的事实，或者是对事实进行错误的推理，LLM 回答不存在的东西的现象被称为幻觉（Hallucination）。 尤其不擅长于最新的技术和最近的热点事件（注：这里排除掉能够使用联网能力的产品），因为 LLM 训练时使用的数据集是有截止日期的。...</div></div></div></a><a class="pagination-related" href="/gdBlog/2025/10/02/%E5%85%83%E8%8A%B3%E6%8E%A5%E5%85%A5DeepSearch/" title="元芳接入DeepSearch"><img class="cover" src="/gdBlog/./img/logoZiyouzhiyi.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-02</div><div class="info-item-2">元芳接入DeepSearch</div></div><div class="info-2"><div class="info-item-1">实现过程部署在虎符上, 因此Flask Web服务, 最后提供HTTP API接口.在元芳上新增工具为[MCP]问答_DeepResearch深度思考_服务,[MCP]问答_arXiv_服务(并没有用到在应用上), 新增应用为Deep Research应用.  首先使用了DashScope翻译服务完成中译英, 因为arXiv的中文搜索不太行 使用官方提供的arXiv库实现arXiv论文检索 最后使用DeepSeek推理模型, 将论文检索的内容作为输入再加上用户原本的输入作为最终的输入给DeepSeekR1模型(在元芳上) 返回1.论文 2.深度思考 3.最后回答 作为输出.相当于实现了[[DeepSearch的论文调研]]  备份在github上了Deepsearch 流程核心功能1. 多语言智能处理 中文检测与翻译 ：自动检测用户查询是否为中文，如果是则调用DashScope API翻译为英文 翻译容错机制 ：翻译失败时回退到原始查询，确保系统稳定性  2. 学术资源搜索 arXiv论文检索 ：将翻译后的英文查询用于搜索相关学术论文 结果格式化 ：提取论文标题和PDF链接，生成...</div></div></div></a><a class="pagination-related" href="/gdBlog/2025/10/01/DeepSearch%E7%9A%84%E8%AE%BA%E6%96%87%E8%B0%83%E7%A0%94/" title="DeepSearch的论文调研"><img class="cover" src="/gdBlog/./img/logoZiyouzhiyi.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-01</div><div class="info-item-2">DeepSearch的论文调研</div></div><div class="info-2"><div class="info-item-1">论文调研综述论文A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications该综述由浙江大学徐仁军和彭静雯撰写，系统研究了Deep Research 系统这一快速发展的领域 —— 这类系统通过整合大型语言模型（LLMs）、先进信息检索技术和自主推理能力，实现复杂研究工作流的自动化；综述分析了 2023 年以来出现的80 多个商业和非商业系统（如 OpenAI&#x2F;DeepResearch、Gemini&#x2F;DeepResearch 等），提出了基于 “基础模型与推理引擎、工具利用与环境交互、任务规划与执行控制、知识合成与输出生成” 的四层技术分类体系，探讨了系统在学术、科学、商业、教育等领域的架构模式与应用适配性，指出当前系统在信息准确性、隐私、知识产权等方面的技术与伦理挑战，并明确了先进推理架构、多模态融合、领域专业化等未来研究方向，同时提供了相关资源库（https://github.com/scienceaix/deepresearch）支持进一步研究 ![[Ob...</div></div></div></a><a class="pagination-related" href="/gdBlog/2025/10/09/Dify%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/" title="Dify本地部署"><img class="cover" src="/gdBlog/./img/logoDify.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-09</div><div class="info-item-2">Dify本地部署</div></div><div class="info-2"><div class="info-item-1">什么是Dify？Dify 是一款开源的大语言模型（LLM）应用开发平台，它巧妙地融合了后端即服务（BaaS）与大型语言模型运维（LLMOps）的核心理念。Dify 的命名源自“Define + Modify”，寓意着开发者可以定义并持续改进其 AI 应用，同时也致力于“为你而做”（Do it for you）。该平台旨在帮助开发者乃至非技术人员，快速构建并上线生产级的生成式 AI 应用，并支持非技术人员便捷地参与 AI 应用的定义与数据运营。 Dify搭建用户既可以通过访问 “https://cloud.dify.ai/” 在线使用 Dify（需要 GitHub 或 Google 账号授权），也可以选择在本地环境中部署 Dify 社区版（此为开源版本）。下文将重点介绍如何基于 Docker Compose 部署 Dify 社区版。在开始安装 Dify 之前，请确保您的设备至少具备 双核（2 core）处理器 和 4GB 以上内存。以下步骤将演示如何在 Mac 系统中运行 Dify。首先，您需要安装 Docker Desktop 以支持 Docker 容器的运行，随后即可通过 Do...</div></div></div></a><a class="pagination-related" href="/gdBlog/2025/09/30/MCP-Model-Context-Protocol%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE/" title="MCP(Model Context Protocol模型上下文协议)"><img class="cover" src="/gdBlog/./img/logoZiyouzhiyi.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-30</div><div class="info-item-2">MCP(Model Context Protocol模型上下文协议)</div></div><div class="info-2"><div class="info-item-1">MCP 起源于 2024 年 11 月 25 日, 定义了应用程序和 AI 模型之间交换上下文信息的方式。这使得开发者能够以一致的方式将各种数据源、工具和功能连接到 AI 模型（一个中间协议层），就像 USB-C 让不同设备能够通过相同的接口连接一样。MCP 的目标是创建一个通用标准，使 AI 应用程序的开发和集成变得更加简单和统一。 起源思考我认为 MCP 的出现是 prompt engineering 发展的产物。更结构化的上下文信息对模型的 performance 提升是显著的。在构造 prompt 时，希望能提供一些更 specific 的信息（比如本地文件，数据库，一些网络实时信息等）给模型，这样模型更容易理解真实场景中的问题。 第一阶段手工输入. 想象一下没有 MCP 之前我们会怎么做？我们可能会人工从数据库中筛选或者使用工具检索可能需要的信息，手动的粘贴到 prompt 中。随着我们要解决的问题越来越复杂，手工把信息引入到 prompt 中会变得越来越困难。 第二阶段 function call. 为了克服手工 prompt 的局限性，许多 LLM 平台（如 Ope...</div></div></div></a><a class="pagination-related" href="/gdBlog/2025/10/02/%E5%85%83%E8%8A%B3%E6%8E%A5%E5%85%A5MCP/" title="元芳接入MCP"><img class="cover" src="/gdBlog/./img/logoZiyouzhiyi.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-02</div><div class="info-item-2">元芳接入MCP</div></div><div class="info-2"><div class="info-item-1">项目特点(写在前面)基于 Flask + MySQL + ChromaDB 的 工具管理系统 ,部署在虎符上,为元芳mcp-client工具提供服务，主要用于管理和搜索各种元芳工具，并集成MCP,向量检索,内含元芳执行器不依赖其他元芳版本只依赖数据库。 返回接口执行失败 123456789&#123;    &quot;log&quot;: [        &#123;            &quot;MCP_select_tool_name&quot;: &quot;工具名称&quot;,            &quot;yf_tool_parameters&quot;: &quot;参数&quot;        &#125;    ],    &quot;error&quot;: &quot;错误信息或最终结果&quot;&#125; 执行成功 123456789101112&#123;    &quot;log&quot;: [        &#123;&quot;name&quot;: &quot;工具1&quot;, &quot;description&quo...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/gdBlog/img/touxiang.jpg" onerror="this.onerror=null;this.src='/gdBlog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">GuoDong</div><div class="author-info-description">碎碎念念 岁岁年年</div><div class="site-data"><a href="/gdBlog/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/gdBlog/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/gdBlog/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://www.douyin.com/" target="_blank" title="douyin"><i class="fab fa-tiktok" style="color: #24292e;"></i></a><a class="social-icon" href="https://www.bilibili.com/" target="_blank" title="bilibili"><i class="fab fa-bilibili" style="color: #24292e;"></i></a><a class="social-icon" href="https://github.com/gaoguodong03" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://leetcode.cn/studyplan/top-100-liked/" target="_blank" title="LeetCode"><i class="fab fa-comments" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">有重要的事情 得去趟南京<br>苦苦刷LeetCode<br>常驻实验室选手<br>健身房小小白</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#AI-%E6%90%9C%E7%B4%A2"><span class="toc-number">1.</span> <span class="toc-text">AI + 搜索</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86"><span class="toc-number">1.1.</span> <span class="toc-text">技术原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AI-%E6%B7%B1%E5%BA%A6%E6%90%9C%E7%B4%A2%EF%BC%88Deep-Search%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">AI + 深度搜索（Deep Search）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Graph-RAG"><span class="toc-number">2.1.</span> <span class="toc-text">Graph RAG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Agentic-RAG"><span class="toc-number">2.2.</span> <span class="toc-text">Agentic RAG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Search"><span class="toc-number">2.3.</span> <span class="toc-text">Deep Search</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AI-%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6%EF%BC%88Deep-Research%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">AI + 深度研究（Deep Research）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Research-%E6%BC%94%E8%BF%9B%E5%8E%86%E5%8F%B2"><span class="toc-number">3.1.</span> <span class="toc-text">Deep Research 演进历史</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Research-%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.2.</span> <span class="toc-text">Deep Research 示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Research-%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.</span> <span class="toc-text">Deep Research 开源实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#assafelovic-gpt-researcher"><span class="toc-number">3.3.1.</span> <span class="toc-text">assafelovic&#x2F;gpt-researcher</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dzhng-deep-research"><span class="toc-number">3.3.2.</span> <span class="toc-text">dzhng&#x2F;deep-research</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sentient-agi-OpenDeepSearch"><span class="toc-number">3.3.3.</span> <span class="toc-text">sentient-agi&#x2F;OpenDeepSearch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%B4%E5%A4%9A"><span class="toc-number">3.3.4.</span> <span class="toc-text">更多</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">5.</span> <span class="toc-text">参考</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Search"><span class="toc-number">5.1.</span> <span class="toc-text">Search</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Search-1"><span class="toc-number">5.2.</span> <span class="toc-text">Deep Search</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Research"><span class="toc-number">5.3.</span> <span class="toc-text">Deep Research</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%93%BE%E6%8E%A5"><span class="toc-number">6.</span> <span class="toc-text">链接</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/gdBlog/2026/01/01/RSS%EF%BC%88Really-Simple-Syndication%EF%BC%88%E7%AE%80%E6%98%93%E4%BF%A1%E6%81%AF%E8%81%9A%E5%90%88%EF%BC%89%EF%BC%89/" title="RSS（Really Simple Syndication（简易信息聚合））">RSS（Really Simple Syndication（简易信息聚合））</a><time datetime="2025-12-31T16:00:00.000Z" title="发表于 2026-01-01 00:00:00">2026-01-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/gdBlog/2025/10/15/%E6%8E%A5%E9%9B%A8%E6%B0%B4/" title="LeeCode接雨水">LeeCode接雨水</a><time datetime="2025-10-14T16:00:00.000Z" title="发表于 2025-10-15 00:00:00">2025-10-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/gdBlog/2025/10/14/%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97/" title="LeeCode最长连续序列">LeeCode最长连续序列</a><time datetime="2025-10-14T00:00:00.000Z" title="发表于 2025-10-14 08:00:00">2025-10-14</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent;"><div class="footer-other"><div class="footer-copyright"></div><div class="footer_custom_text"><style>
  .footer {
    text-align: center;
    position: relative;
  }
  .social-links {
    display: flex;
    justify-content: center;
    gap: 1.5rem;
    flex-wrap: wrap;
  }
  .social-links i {
    color: #000000;
  }
  .social-link {
    color: #000000;
    font-size: 1.2rem;
    transition: all 0.3s ease;
    display: inline-flex;
    align-items: center;
    justify-content: center;
    width: 2.5rem;
    height: 2.5rem;
    border-radius: 50%;
    background: rgba(0, 0, 0, 0.1);
  }
  .social-link:hover {
    color: #333333;
    background: rgba(0, 0, 0, 0.2);
    transform: translateY(-3px) scale(1.2);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
    text-decoration: none !important; 
  }
  .footer p {
    margin: 0.5rem 0;
    line-height: 1;
  }
  .copyright {
    font-size: 1.1rem; 
    color: #000000;
    font-weight: 400;
  }
  .tagline {
    font-size: 0.8rem;
    color: #333333;
    font-style: italic;
    font-weight: 500;
  }
  .visitor-count {
    font-size: 0.75rem;
    color: rgba(0, 0, 0, 0.7);
    font-weight: 300;
  }
  #visitorCount {
    font-weight: bold;
  }
</style>
<div class="footer">
  <p class="copyright">© 2025 果冻小配方 - 所有权利保留</p>
  <p class="tagline">> 碎碎念念 岁岁年年 <</p>
  <p class="visitor-count">访问量: <span id="visitorCount">1024</span> | 你是第 <span id="dailyVisitor">1</span> 位今日访客</p>
</div>
<script>
  // 确保DOM加载完成后执行
  document.addEventListener('DOMContentLoaded', function() {
    // 模拟访问量增长
    function updateVisitorCount() {
      const countElement = document.getElementById('visitorCount');
      let count = parseInt(countElement.textContent) || 1024;
      // 从localStorage获取或初始化计数
      const storedCount = localStorage.getItem('totalVisitors');
      if (storedCount) {
        count = parseInt(storedCount);
        countElement.textContent = count;
      }
      // 每日访客计数
      const today = new Date().toDateString();
      const dailyData = JSON.parse(localStorage.getItem('dailyVisitors') || '{"date":"", "count":0}');
      if (dailyData.date !== today) {
        dailyData.date = today;
        dailyData.count = 0;
      }
      dailyData.count += 1;
      document.getElementById('dailyVisitor').textContent = dailyData.count;
      localStorage.setItem('dailyVisitors', JSON.stringify(dailyData));
      // 每30秒随机增加访问量
      setInterval(() => {
        count += Math.floor(Math.random() * 3);
        countElement.textContent = count;
        localStorage.setItem('totalVisitors', count.toString());
      }, 30000);
    }
    updateVisitorCount();
    // 添加点击动画效果
    const socialLinks = document.querySelectorAll('.social-link');
    socialLinks.forEach(link => {
      link.addEventListener('click', function() {
        this.style.transform = 'scale(0.9)';
        setTimeout(() => {
          this.style.transform = '';
        }, 300);
      });
    });
  });
</script>
</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/gdBlog/js/utils.js"></script><script src="/gdBlog/js/main.js"></script><div class="js-pjax"></div><script src="/config/js/happy-title.js" async></script><script src="/config/js/foot.js" async></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_categories_card_injector_config(){
    // 检查容器是否存在
    var parent_div_git = document.getElementById('recent-posts');
    // 如果容器不存在，则动态创建
    if (!parent_div_git) {
      console.warn('butterfly_categories_card: 挂载容器不存在，正在动态创建...');
      // 创建新容器（默认插入到页面主体顶部）
      parent_div_git = document.createElement('div');
      parent_div_git.id = 'recent-posts'; // 赋予配置的ID
      document.querySelector('#page').prepend(parent_div_git); // 插入到 #content-inner 内
    }
    var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 950px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 800px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(/img/logo.jpg);"> <a class="categoryBar-list-link" href="/categories/果冻的日记本/">果冻的日记本</a><span class="categoryBar-list-count">4</span><span class="categoryBar-list-descr">果冻的航海日记</span></li><li class="categoryBar-list-item" style="background:url(/img/logo.jpg);"> <a class="categoryBar-list-link" href="/categories/果冻的理论学习/">果冻的理论学习</a><span class="categoryBar-list-count">8</span><span class="categoryBar-list-descr">Hexo</span></li><li class="categoryBar-list-item" style="background:url(/img/logo.jpg);"> <a class="categoryBar-list-link" href="/categories/果冻的奇妙小工具/">果冻的奇妙小工具</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr">果冻的奇妙小工具</span></li><li class="categoryBar-list-item" style="background:url(/img/logo.jpg);"> <a class="categoryBar-list-link" href="/categories/果冻的航海日志/">果冻的航海日志</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr">果冻的日记本</span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" href="/categories/果冻的科普专区/">果冻的科普专区</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" href="/categories/Hexo/">Hexo</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr"></span></li><li class="categoryBar-list-item" style="background:url(undefined);"> <a class="categoryBar-list-link" href="/categories/果冻的LeetCode刷题/">果冻的LeetCode刷题</a><span class="categoryBar-list-count">5</span><span class="categoryBar-list-descr"></span></li></ul></div></div>';
    console.log('已挂载 butterfly_categories_card');
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
  }
  // 路径匹配逻辑（使用 startsWith）
  if (location.pathname.startsWith('/categories/') || '/categories/' === 'all') {
    butterfly_categories_card_injector_config();
  }
  </script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '300ms');
    arr[i].setAttribute('data-wow-delay', '0ms');
    arr[i].setAttribute('data-wow-offset', '0');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>